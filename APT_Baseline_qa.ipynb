{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapHelper:\n",
    "    \n",
    "    def append_to_list(map_with_list_as_value, map_key, new_list_element):\n",
    "        existing_list = map_with_list_as_value.get(map_key, [])\n",
    "        new_list = existing_list + [new_list_element]\n",
    "        map_with_list_as_value[map_key] = new_list\n",
    "    \n",
    "    def append_to_set(map_with_set_as_value, map_key, new_set_element):\n",
    "        existing_set = map_with_set_as_value.get(map_key, set())\n",
    "        existing_set.add(new_set_element)\n",
    "        map_with_set_as_value[map_key] = existing_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerRelevance:\n",
    "    \"\"\"\n",
    "        Makes no distinction between \n",
    "        PotentiallyUseful and Bad comments\n",
    "    \"\"\"\n",
    "    \n",
    "    INT_GOOD = 1\n",
    "    GOOD = \"Good\"\n",
    "    \n",
    "    POTENTIALLY_USEFUL = \"PotentiallyUseful\"\n",
    "    \n",
    "    INT_BAD = 0\n",
    "    BAD = \"Bad\"\n",
    "    \n",
    "    \n",
    "    def to_number(string_relevance):\n",
    "        return AnswerRelevance.INT_GOOD \\\n",
    "            if string_relevance == AnswerRelevance.GOOD \\\n",
    "            else AnswerRelevance.INT_BAD\n",
    "    \n",
    "    \n",
    "    def from_number(int_relevance):\n",
    "        return AnswerRelevance.GOOD \\\n",
    "            if string_relevance == AnswerRelevance.INT_GOOD \\\n",
    "            else AnswerRelevance.BAD\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thread:\n",
    "    \n",
    "    def __init__(self, question, answers):\n",
    "        self.question = question\n",
    "        self.answers = answers\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.question.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.question.__repr__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadCollection:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.by_topic = {}\n",
    "    \n",
    "    def add(self, string_topic, thread):\n",
    "        MapHelper.append_to_list(self.by_topic, string_topic, thread)\n",
    "    \n",
    "    def get(self, string_topic):\n",
    "        return self.by_topic.get(string_topic, [])\n",
    "    \n",
    "    def topics(self):\n",
    "        return list(self.by_topic.keys())\n",
    "\n",
    "    def topic_thread_pairs(self):\n",
    "        return self.by_topic.items()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class QuestionData:\n",
    "    \n",
    "    STRING_CATEGORY_KEY = \"RELQ_CATEGORY\"\n",
    "    \n",
    "    def __init__(self, subject, body):\n",
    "        self.subject = subject\n",
    "        self.body = body\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.body)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "        \n",
    "        \n",
    "class AnswerData:\n",
    "    \n",
    "    STRING_RELEVANCE_KEY = \"RELC_RELEVANCE2RELQ\"\n",
    "    STRING_USERNAME_KEY = \"RELC_USERNAME\"\n",
    "    STRING_DATE_KEY = \"RELC_DATE\"\n",
    "    STRING_ID_KEY = \"RELC_ID\"\n",
    "    \n",
    "    def __init__(self, metadata, body):\n",
    "        self.metadata = metadata\n",
    "        self.body = body\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.body)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    \n",
    "class Metadata:\n",
    "    \n",
    "    def __init__(self, user, date, relevance):\n",
    "        self.user = user\n",
    "        self.date = date\n",
    "        self.relevance = relevance\n",
    "    \n",
    "    \n",
    "QuestionAnswerPair = namedtuple('QuestionAnswerPair', ['question', 'answer', 'data'])\n",
    "\n",
    "# set data to None by default\n",
    "QuestionAnswerPair.__new__.__defaults__ = (None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_question_data(node_question):\n",
    "    subject = node_question[0]\n",
    "    body = node_question[1]\n",
    "    \n",
    "    return QuestionData(subject.text, body.text)\n",
    "\n",
    "\n",
    "def to_answer_data(node_thread_answers):\n",
    "    f = lambda node: AnswerData(Metadata(node.attrib[AnswerData.STRING_USERNAME_KEY],\n",
    "                                         node.attrib[AnswerData.STRING_DATE_KEY],\n",
    "                                         AnswerRelevance.to_number(node.attrib[AnswerData.STRING_RELEVANCE_KEY])), \n",
    "                                node[0].text)\n",
    "    \n",
    "    return [f(node) for node in node_thread_answers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import XMLCorpusReader, XMLCorpusView\n",
    "\n",
    "def load_data(string_basedir, string_filenames_in_basedir, subtask_A=False):\n",
    "    for string_filename in string_filenames_in_basedir:\n",
    "        corpus_reader = XMLCorpusReader(string_basedir, string_filename)\n",
    "        \n",
    "        for root_node in corpus_reader.xml():\n",
    "            if not subtask_A:\n",
    "                node_thread = root_node[0]\n",
    "            else:\n",
    "                node_thread = root_node\n",
    "            node_thread_question = node_thread[0]\n",
    "            node_thread_answers = node_thread[1:]\n",
    "\n",
    "            thread_question = to_question_data(node_thread_question)\n",
    "            thread_answers = to_answer_data(node_thread_answers)\n",
    "\n",
    "            thread = Thread(thread_question, thread_answers)        \n",
    "            string_topic = node_thread_question.attrib[QuestionData.STRING_CATEGORY_KEY]\n",
    "            \n",
    "            yield string_topic, thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import *\n",
    "\n",
    "\n",
    "def get_limited_generator(string_basedir,\n",
    "                          list_string_filenames_in_basedir,\n",
    "                          start_index_inclusive, \n",
    "                          end_index_exclusive = None, \n",
    "                          step = None,\n",
    "                         subtask_A = False):\n",
    "    data_generator = load_data(string_basedir, list_string_filenames_in_basedir, subtask_A)\n",
    "    return islice(data_generator, start_index_inclusive, end_index_exclusive, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_relevant(question, list_relevant, int_how_many):\n",
    "    for i in range(int_how_many):\n",
    "        question = QuestionData(str(question.subject), str(question.body))\n",
    "        yield QuestionAnswerPair(question, list_relevant[i % len(list_relevant)] )\n",
    "    \n",
    "\n",
    "def get_data(data_generator, do_repeat_relevant = True):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for topic, thread in data_generator:\n",
    "        question = thread.question\n",
    "        list_relevant = []\n",
    "        \n",
    "        for answer in thread.answers:\n",
    "            question = QuestionData(str(question.subject), str(question.body))\n",
    "            question_answer_pair = QuestionAnswerPair(question, answer)\n",
    "            \n",
    "            X += [ question_answer_pair ]\n",
    "            y += [ answer.metadata.relevance ]\n",
    "            \n",
    "            if answer.metadata.relevance == AnswerRelevance.INT_GOOD:\n",
    "                list_relevant += [answer]\n",
    "        \n",
    "        num_relevant = len(list_relevant)\n",
    "        num_irrelevant = len(thread.answers) - num_relevant\n",
    "        \n",
    "        if num_relevant < num_irrelevant \\\n",
    "            and do_repeat_relevant \\\n",
    "            and num_relevant != 0:\n",
    "                \n",
    "            delta = num_irrelevant - num_relevant\n",
    "            \n",
    "            X += repeat_relevant(question, list_relevant, delta)\n",
    "            y += [ AnswerRelevance.INT_GOOD for i in range(delta) ]\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericItemTransformer:\n",
    "    \n",
    "    def __init__(self, generic_transformation):\n",
    "        self.generic_transformation = generic_transformation\n",
    "    \n",
    "    def transform(self, generic_input, y=None):        \n",
    "        return self.generic_transformation(generic_input)\n",
    "    \n",
    "    def fit(self, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return 1 - cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "\n",
    "\n",
    "def to_content_generator(non_tokenized_qa_pairs):\n",
    "    for qa_pair in non_tokenized_qa_pairs:\n",
    "        yield qa_pair.question.body\n",
    "        yield qa_pair.answer.body\n",
    "        \n",
    "        \n",
    "def tfidf_calc(non_tokenized_qa_pairs, \n",
    "               tfidf_vectorizer):\n",
    "    generator = to_content_generator(non_tokenized_qa_pairs)\n",
    "    sparse_matrix = tfidf_vectorizer.fit_transform(generator)\n",
    "    sparse_matrix_nrows = sparse_matrix.shape[0]\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(0, sparse_matrix_nrows, 2):\n",
    "        question_sparse_vector = sparse_matrix.getrow(i)\n",
    "        answer_sparse_vector = sparse_matrix.getrow(i + 1)\n",
    "        \n",
    "        similarity = cosine_similarity(question_sparse_vector.todense(), \n",
    "                                       answer_sparse_vector.todense())\n",
    "        \n",
    "        similarities += [[similarity]]\n",
    "        \n",
    "    return similarities\n",
    "    \n",
    "\n",
    "def get_tfidf_transformer():\n",
    "    tfidf_vectorizer= TfidfVectorizer(stop_words='english')\n",
    "    return GenericItemTransformer(\n",
    "        lambda non_tokenized_qa_pairs: tfidf_calc(non_tokenized_qa_pairs, tfidf_vectorizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "def get_pipeline():   \n",
    "    non_tokenized_features = FeatureUnion([\n",
    "        ('tfidf', get_tfidf_transformer())\n",
    "    ])\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('features', make_union(non_tokenized_features)),\n",
    "        ('nan_remover', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive / negative examples:  17711 / 16713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/spatial/distance.py:329: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tfidf', <__main__.GenericItemTransformer object at 0x7f91e9a84b38>)],\n",
       "       transformer_weights=None))],\n",
       "       trans...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import collections\n",
    "\n",
    "\n",
    "data_generator = get_limited_generator('train', ['SemEval2016-Task3-CQA-QL-train-part1.xml', 'SemEval2016-Task3-CQA-QL-train-part2.xml'], \n",
    "                                       0, None, None)\n",
    "\n",
    "X, y = get_data(data_generator, do_repeat_relevant=True)\n",
    "\n",
    "dict_y_value_counts = collections.Counter(y)\n",
    "n_negative = dict_y_value_counts[0]\n",
    "n_positive = dict_y_value_counts[1]\n",
    "\n",
    "print(\"Number of positive / negative examples: \", n_positive, \"/\", n_negative )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "classifier = GridSearchCV(svm.SVC(), tuned_parameters, cv=5)\n",
    "pipeline = get_pipeline()\n",
    "make_pipeline(pipeline, classifier).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def mean_average_precision(list_y_true, list_y_score):\n",
    "    ap = 0.0\n",
    "    \n",
    "    for (y_true, y_score) in zip(list_y_true, list_y_score):\n",
    "        ap += average_precision_score(y_true, y_score)\n",
    "        \n",
    "    return ap / len(list_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/spatial/distance.py:329: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:  0.600652552083\n",
      "acc 0.594625998548\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.60      0.59      3364\n",
      "          1       0.61      0.59      0.60      3521\n",
      "\n",
      "avg / total       0.59      0.59      0.59      6885\n",
      "\n",
      "{'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_test = pipeline.fit_transform(X_test)\n",
    "\n",
    "classifier_output = classifier.decision_function(X_test)\n",
    "output_mean_average_precision = mean_average_precision([y_test], [classifier_output])\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "print('MAP: ', output_mean_average_precision)\n",
    "print('acc', accuracy_score(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = get_limited_generator('train', ['SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml'], \n",
    "                                       0, None, None, True)\n",
    "\n",
    "X, y = get_data(data_generator, do_repeat_relevant=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnswerPair(question=is there any place i can find scented massage oils in qatar?, answer=Yes. It is right behind Kahrama in the National area., data=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
