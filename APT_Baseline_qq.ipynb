{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapHelper:\n",
    "    \n",
    "    def append_to_list(map_with_list_as_value, map_key, new_list_element):\n",
    "        existing_list = map_with_list_as_value.get(map_key, [])\n",
    "        new_list = existing_list + [new_list_element]\n",
    "        map_with_list_as_value[map_key] = new_list\n",
    "    \n",
    "    def append_to_set(map_with_set_as_value, map_key, new_set_element):\n",
    "        existing_set = map_with_set_as_value.get(map_key, set())\n",
    "        existing_set.add(new_set_element)\n",
    "        map_with_set_as_value[map_key] = existing_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionRelevance:\n",
    "    \"\"\"\n",
    "        Makes no distinction between \n",
    "        PerfectMatch and Relevant questions\n",
    "    \"\"\"\n",
    "    \n",
    "    INT_RELEVANT = 1\n",
    "    RELEVANT = \"Relevant\"\n",
    "    \n",
    "    PERFECT_MACH = \"PerfectMatch\"\n",
    "    \n",
    "    INT_IRRELEVANT = 0\n",
    "    IRRELEVANT = \"Irrelevant\"\n",
    "    \n",
    "    \n",
    "    def to_number(string_relevance):\n",
    "        return QuestionRelevance.INT_IRRELEVANT\\\n",
    "            if string_relevance == QuestionRelevance.IRRELEVANT \\\n",
    "            else QuestionRelevance.INT_RELEVANT\n",
    "    \n",
    "    \n",
    "    def from_number(int_relevance):\n",
    "        return QuestionRelevance.IRRIELEVANT \\\n",
    "            if string_relevance == QuestionRelevance.INT_IRRELEVANT \\\n",
    "            else QuestionRelevance.RELEVANT\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thread:\n",
    "    \n",
    "    def __init__(self, question, rel_questions):\n",
    "        self.question = question\n",
    "        self.rel_questions = rel_questions\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.question.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.question.__repr__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class QuestionData:\n",
    "    \n",
    "    def __init__(self, subject, body):\n",
    "        self.subject = subject\n",
    "        self.body = body\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.body)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "        \n",
    "        \n",
    "class RelQuestionData:\n",
    "    \n",
    "    STRING_RELEVANCE_KEY = \"RELQ_RELEVANCE2ORGQ\"\n",
    "    STRING_USERNAME_KEY = \"RELQ_USERNAME\"\n",
    "    STRING_DATE_KEY = \"RELQ_DATE\"\n",
    "    STRING_ID_KEY = \"RELQ_ID\"\n",
    "    \n",
    "    def __init__(self, metadata, subject, body):\n",
    "        self.metadata = metadata\n",
    "        self.subject = subject\n",
    "        self.body = body\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.body)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    \n",
    "class Metadata:\n",
    "    \n",
    "    def __init__(self, user, date, relevance):\n",
    "        self.user = user\n",
    "        self.date = date\n",
    "        self.relevance = relevance\n",
    "    \n",
    "    \n",
    "QuestionQuestionPair = namedtuple('QuestionQuestionPair', ['question', 'rel_question', 'data'])\n",
    "\n",
    "# set data to None by default\n",
    "QuestionQuestionPair.__new__.__defaults__ = (None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_question_data(node_question):\n",
    "    subject = node_question[0]\n",
    "    body = node_question[1]\n",
    "    \n",
    "    return QuestionData(subject.text, body.text)\n",
    "\n",
    "\n",
    "def to_rel_question_data(node_rel_questions):\n",
    "    f = lambda node: RelQuestionData(Metadata(node.attrib[RelQuestionData.STRING_USERNAME_KEY],\n",
    "                                         node.attrib[RelQuestionData.STRING_DATE_KEY],\n",
    "                                         QuestionRelevance.to_number(node.attrib[RelQuestionData.STRING_RELEVANCE_KEY])), \n",
    "                                node[0].text, node[1].text)\n",
    "    \n",
    "    return [f(node) for node in node_rel_questions if node[1].text is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import XMLCorpusReader, XMLCorpusView\n",
    "\n",
    "def load_data(string_basedir, string_filenames_in_basedir):\n",
    "    \n",
    "    for string_filename in string_filenames_in_basedir:\n",
    "        corpus_reader = XMLCorpusReader(string_basedir, string_filename)\n",
    "        i = 0\n",
    "        node_rel_questions = []\n",
    "        for root_node in corpus_reader.xml():\n",
    "            node_question = root_node\n",
    "            node_rel_questions.append(root_node[2][0])\n",
    "            i += 1\n",
    "            if i == 10:\n",
    "                thread_question = to_question_data(node_question)\n",
    "                thread_rel_questions = to_rel_question_data(node_rel_questions)\n",
    "\n",
    "                thread = Thread(thread_question, thread_rel_questions)        \n",
    "                string_topic = \"\"\n",
    "                \n",
    "                i = 0\n",
    "                node_rel_questions = []\n",
    "            \n",
    "                yield string_topic, thread\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import *\n",
    "\n",
    "\n",
    "def get_limited_generator(string_basedir,\n",
    "                          list_string_filenames_in_basedir,\n",
    "                          start_index_inclusive, \n",
    "                          end_index_exclusive = None, \n",
    "                          step = None):\n",
    "    data_generator = load_data(string_basedir, list_string_filenames_in_basedir)\n",
    "    return islice(data_generator, start_index_inclusive, end_index_exclusive, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_relevant(question, list_relevant, int_how_many):\n",
    "    for i in range(int_how_many):\n",
    "        question = QuestionData(str(question.subject), str(question.body))\n",
    "        yield QuestionQuestionPair(question, list_relevant[i % len(list_relevant)] )\n",
    "    \n",
    "\n",
    "def get_data(data_generator, do_repeat_relevant = False):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for topic, thread in data_generator:\n",
    "        question = thread.question\n",
    "        list_relevant = []\n",
    "        \n",
    "        for rel_question in thread.rel_questions:\n",
    "            question = QuestionData(str(question.subject), str(question.body))\n",
    "            question_question_pair = QuestionQuestionPair(question, rel_question)\n",
    "            \n",
    "            X += [ question_question_pair ]\n",
    "            y += [ rel_question.metadata.relevance ]\n",
    "    \n",
    "            if rel_question.metadata.relevance == QuestionRelevance.INT_RELEVANT:\n",
    "                list_relevant += [rel_question]\n",
    "        \n",
    "        num_relevant = len(list_relevant)\n",
    "        num_irrelevant = len(thread.rel_questions) - num_relevant\n",
    "        \n",
    "        if num_relevant < num_irrelevant \\\n",
    "            and do_repeat_relevant \\\n",
    "            and num_relevant != 0:\n",
    "                \n",
    "            delta = num_irrelevant - num_relevant\n",
    "            \n",
    "            X += repeat_relevant(question, list_relevant, delta)\n",
    "            y += [ QuestionRelevance.INT_RELEVANT for i in range(delta) ]\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericItemTransformer:\n",
    "    \n",
    "    def __init__(self, generic_transformation):\n",
    "        self.generic_transformation = generic_transformation\n",
    "    \n",
    "    def transform(self, generic_input, y=None):        \n",
    "        return self.generic_transformation(generic_input)\n",
    "    \n",
    "    def fit(self, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return 1 - cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "\n",
    "\n",
    "def to_content_generator(non_tokenized_qq_pairs):\n",
    "    for qq_pair in non_tokenized_qq_pairs:\n",
    "        yield qq_pair.question.body\n",
    "        yield qq_pair.rel_question.body\n",
    "        \n",
    "        \n",
    "def tfidf_calc(non_tokenized_qq_pairs, \n",
    "               tfidf_vectorizer):\n",
    "    generator = to_content_generator(non_tokenized_qq_pairs)\n",
    "    sparse_matrix = tfidf_vectorizer.fit_transform(generator)\n",
    "    sparse_matrix_nrows = sparse_matrix.shape[0]\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(0, sparse_matrix_nrows, 2):\n",
    "        question_sparse_vector = sparse_matrix.getrow(i)\n",
    "        rel_question_sparse_vector = sparse_matrix.getrow(i + 1)\n",
    "        \n",
    "        similarity = cosine_similarity(question_sparse_vector.todense(), \n",
    "                                       rel_question_sparse_vector.todense())\n",
    "        \n",
    "        similarities += [[similarity]]\n",
    "        \n",
    "    return similarities\n",
    "    \n",
    "\n",
    "def get_tfidf_transformer():\n",
    "    tfidf_vectorizer= TfidfVectorizer(stop_words='english')\n",
    "    return GenericItemTransformer(\n",
    "        lambda non_tokenized_qq_pairs: tfidf_calc(non_tokenized_qq_pairs, tfidf_vectorizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "def get_pipeline():   \n",
    "    non_tokenized_features = FeatureUnion([\n",
    "        ('tfidf', get_tfidf_transformer())\n",
    "    ])\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('features', make_union(non_tokenized_features)),\n",
    "        ('nan_remover', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive / negative examples:  2552 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/spatial/distance.py:329: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tfidf', <__main__.GenericItemTransformer object at 0x7f97368df7b8>)],\n",
       "       transformer_weights=None))],\n",
       "       trans...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import collections\n",
    "\n",
    "\n",
    "data_generator = get_limited_generator('train', ['SemEval2016-Task3-CQA-QL-train-part1.xml', 'SemEval2016-Task3-CQA-QL-train-part1.xml'], \n",
    "                                       0, None, None)\n",
    "\n",
    "X, y = get_data(data_generator, do_repeat_relevant=True)\n",
    "\n",
    "\n",
    "dict_y_value_counts = collections.Counter(y)\n",
    "n_negative = dict_y_value_counts[0]\n",
    "n_positive = dict_y_value_counts[1]\n",
    "\n",
    "print(\"Number of positive / negative examples: \", n_positive, \"/\", n_negative )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "classifier = GridSearchCV(svm.SVC(), tuned_parameters, cv=5)\n",
    "pipeline = get_pipeline()\n",
    "make_pipeline(pipeline, classifier).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def mean_average_precision(list_y_true, list_y_score):\n",
    "    ap = 0.0\n",
    "    \n",
    "    for (y_true, y_score) in zip(list_y_true, list_y_score):\n",
    "        ap += average_precision_score(y_true, y_score)\n",
    "        \n",
    "    return ap / len(list_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/spatial/distance.py:329: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:  0.72377456914\n",
      "acc 0.646341463415\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.82      0.69       461\n",
      "          1       0.76      0.49      0.60       523\n",
      "\n",
      "avg / total       0.68      0.65      0.64       984\n",
      "\n",
      "{'gamma': 0.001, 'C': 1000, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_test = pipeline.fit_transform(X_test)\n",
    "\n",
    "classifier_output = classifier.decision_function(X_test)\n",
    "output_mean_average_precision = mean_average_precision([y_test], [classifier_output])\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "print('MAP: ', output_mean_average_precision)\n",
    "print('acc', accuracy_score(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
