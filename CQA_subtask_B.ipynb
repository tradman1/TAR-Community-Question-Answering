{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CQA_subtask_B.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1O3ueNlkbvsND4aZwfi0TGVwPAI-O-grU","timestamp":1528664667752},{"file_id":"1b5Jp0oLJ_s6cDivcDgqf2VhgDWlUo3Mp","timestamp":1528664285302},{"file_id":"1sYihbrm9wIlGc6bSHLTL_udzPgE9ap9x","timestamp":1528362171126},{"file_id":"1hETXgN9L3bmICZeSvHLFBIaWhJiwL3aH","timestamp":1527939534659}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"r5eknXHuhR6y","colab_type":"text"},"cell_type":"markdown","source":["# Community Question Answering (Subtask B)"]},{"metadata":{"id":"4PrxC8FP8Qu0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"84445a27-18b5-4e7d-8e91-ed101790d7d8","executionInfo":{"status":"ok","timestamp":1528742350606,"user_tz":-120,"elapsed":8273,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","from keras.preprocessing.text import *\n","from keras.preprocessing.sequence import *\n","from keras.models import *\n","from keras.layers import *\n","from keras.utils import *\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras.callbacks import ModelCheckpoint\n","import time\n","import numpy as np\n","import json\n","import h5py\n","from google.colab import files"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"X-xjWCPwlnXL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":318},"outputId":"4e3a4eff-fe19-4247-9525-326b525e95ce","executionInfo":{"status":"ok","timestamp":1528742357602,"user_tz":-120,"elapsed":1619,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["import tensorflow, keras\n","print(\"Tensorflow version \", tensorflow.__version__)\n","print(\"Keras version \", keras.__version__)\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tensorflow version  1.8.0\n","Keras version  2.1.6\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 2029353060459652342, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11287966516\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 12570430546364783582\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"8K0n43rqOVe4","colab_type":"text"},"cell_type":"markdown","source":["##acquire dataset"]},{"metadata":{"id":"dhBCdywi8bp1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2335},"outputId":"83ecc024-16a5-455a-ef82-a64e6207b6ae","executionInfo":{"status":"ok","timestamp":1528742434927,"user_tz":-120,"elapsed":77259,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["# download and unzip embeddings and dataset\n","!wget -O glove.zip http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -o glove.zip -d glove\n","!wget -O task3-cqa.zip http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-cqa-ql-traindev-v3.2.zip\n","!unzip -o task3-cqa.zip -d data\n","!wget -O test.zip http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017_task3_test.zip\n","#!wget -O test.zip http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017_task3_test_input_abcd.zip\n","!unzip -o test.zip -d test_data"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2018-06-11 18:39:18--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2018-06-11 18:39:19--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.zip’\n","\n"],"name":"stdout"},{"output_type":"stream","text":["glove.zip           100%[===================>] 822.24M  14.7MB/s    in 43s     \n","\n","2018-06-11 18:40:02 (19.0 MB/s) - ‘glove.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.zip\n","  inflating: glove/glove.6B.50d.txt  \n","  inflating: glove/glove.6B.100d.txt  \n","  inflating: glove/glove.6B.200d.txt  \n","  inflating: glove/glove.6B.300d.txt  \n","--2018-06-11 18:40:27--  http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-cqa-ql-traindev-v3.2.zip\n","Resolving alt.qcri.org (alt.qcri.org)... 212.71.235.101\n","Connecting to alt.qcri.org (alt.qcri.org)|212.71.235.101|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21555267 (21M) [application/zip]\n","Saving to: ‘task3-cqa.zip’\n","\n","task3-cqa.zip       100%[===================>]  20.56M  14.4MB/s    in 1.4s    \n","\n","2018-06-11 18:40:29 (14.4 MB/s) - ‘task3-cqa.zip’ saved [21555267/21555267]\n","\n","Archive:  task3-cqa.zip\n","   creating: data/v3.2/\n","  inflating: data/v3.2/.DS_Store     \n","   creating: data/__MACOSX/\n","   creating: data/__MACOSX/v3.2/\n","  inflating: data/__MACOSX/v3.2/._.DS_Store  \n","   creating: data/v3.2/dev/\n","  inflating: data/v3.2/dev/SemEval2016-Task3-CQA-QL-dev-subtaskA-with-multiline.xml  \n","   creating: data/__MACOSX/v3.2/dev/\n","  inflating: data/__MACOSX/v3.2/dev/._SemEval2016-Task3-CQA-QL-dev-subtaskA-with-multiline.xml  \n","  inflating: data/v3.2/dev/SemEval2016-Task3-CQA-QL-dev-subtaskA.xml  \n","  inflating: data/__MACOSX/v3.2/dev/._SemEval2016-Task3-CQA-QL-dev-subtaskA.xml  \n","  inflating: data/v3.2/dev/SemEval2016-Task3-CQA-QL-dev-with-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/dev/._SemEval2016-Task3-CQA-QL-dev-with-multiline.xml  \n","  inflating: data/v3.2/dev/SemEval2016-Task3-CQA-QL-dev.xml  \n","  inflating: data/__MACOSX/v3.2/dev/._SemEval2016-Task3-CQA-QL-dev.xml  \n","  inflating: data/__MACOSX/v3.2/._dev  \n","  inflating: data/v3.2/README.txt    \n","  inflating: data/__MACOSX/v3.2/._README.txt  \n","   creating: data/v3.2/train/\n","  inflating: data/v3.2/train/.DS_Store  \n","   creating: data/__MACOSX/v3.2/train/\n","  inflating: data/__MACOSX/v3.2/train/._.DS_Store  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part1-subtaskA-with-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part1-subtaskA-with-multiline.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part1-subtaskA.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part1-with-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part1-with-multiline.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part1.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part1.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part2-subtaskA-with-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part2-subtaskA-with-multiline.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part2-subtaskA.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part2-subtaskA.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part2-with-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part2-with-multiline.xml  \n","  inflating: data/v3.2/train/SemEval2016-Task3-CQA-QL-train-part2.xml  \n","  inflating: data/__MACOSX/v3.2/train/._SemEval2016-Task3-CQA-QL-train-part2.xml  \n","  inflating: data/__MACOSX/v3.2/._train  \n","   creating: data/v3.2/train-more-for-subtaskA-from-2015/\n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/.DS_Store  \n","   creating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/\n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._.DS_Store  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-dev-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-dev-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-dev-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-dev-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-dev-reformatted-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-dev-reformatted-multiline.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-test-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-test-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-test-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-test-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-test-reformatted-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-test-reformatted-multiline.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-train-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-train-reformatted-excluding-2016-questions-cleansed.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-train-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-train-reformatted-excluding-2016-questions-multiline.xml  \n","  inflating: data/v3.2/train-more-for-subtaskA-from-2015/SemEval2015-Task3-CQA-QL-train-reformatted-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/train-more-for-subtaskA-from-2015/._SemEval2015-Task3-CQA-QL-train-reformatted-multiline.xml  \n","  inflating: data/__MACOSX/v3.2/._train-more-for-subtaskA-from-2015  \n","  inflating: data/__MACOSX/._v3.2    \n","--2018-06-11 18:40:32--  http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017_task3_test.zip\n","Resolving alt.qcri.org (alt.qcri.org)... 212.71.235.101\n","Connecting to alt.qcri.org (alt.qcri.org)|212.71.235.101|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6586572 (6.3M) [application/zip]\n","Saving to: ‘test.zip’\n","\n","test.zip             12%[=>                  ] 814.59K  1.47MB/s               "],"name":"stdout"},{"output_type":"stream","text":["\rtest.zip             83%[===============>    ]   5.23M  6.47MB/s               \rtest.zip            100%[===================>]   6.28M  7.73MB/s    in 0.8s    \r\n","\r\n","2018-06-11 18:40:33 (7.73 MB/s) - ‘test.zip’ saved [6586572/6586572]\r\n","\n","Archive:  test.zip\n","   creating: test_data/SemEval2017_task3_test/\n","  inflating: test_data/SemEval2017_task3_test/.DS_Store  \n","   creating: test_data/__MACOSX/\n","   creating: test_data/__MACOSX/SemEval2017_task3_test/\n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/._.DS_Store  \n","   creating: test_data/SemEval2017_task3_test/Arabic/\n","  inflating: test_data/SemEval2017_task3_test/Arabic/.DS_Store  \n","   creating: test_data/__MACOSX/SemEval2017_task3_test/Arabic/\n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/Arabic/._.DS_Store  \n","  inflating: test_data/SemEval2017_task3_test/Arabic/SemEval2017-Task3-CQA-MD-test.xml.gz  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/Arabic/._SemEval2017-Task3-CQA-MD-test.xml.gz  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/._Arabic  \n","   creating: test_data/SemEval2017_task3_test/English/\n","  inflating: test_data/SemEval2017_task3_test/English/.DS_Store  \n","   creating: test_data/__MACOSX/SemEval2017_task3_test/English/\n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/English/._.DS_Store  \n","  inflating: test_data/SemEval2017_task3_test/English/SemEval2017-task3-English-test-subtaskA.xml  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/English/._SemEval2017-task3-English-test-subtaskA.xml  \n","  inflating: test_data/SemEval2017_task3_test/English/SemEval2017-task3-English-test.xml  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/English/._SemEval2017-task3-English-test.xml  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/._English  \n","  inflating: test_data/SemEval2017_task3_test/SemEval2017_task3_test_ABCD_README.txt  \n","  inflating: test_data/__MACOSX/SemEval2017_task3_test/._SemEval2017_task3_test_ABCD_README.txt  \n","  inflating: test_data/__MACOSX/._SemEval2017_task3_test  \n"],"name":"stdout"}]},{"metadata":{"id":"IUpYCjDXwoc7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_dir = 'data/v3.2/train/'\n","dev_dir = 'data/v3.2/dev/'\n","test_dir = 'test_data/SemEval2017_task3_test/English/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c8rS0nxeONnF","colab_type":"text"},"cell_type":"markdown","source":["##preprocessing classes"]},{"metadata":{"id":"h-J_EpXcTu4C","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class MapHelper:\n","    \n","    def append_to_list(map_with_list_as_value, map_key, new_list_element):\n","        existing_list = map_with_list_as_value.get(map_key, [])\n","        new_list = existing_list + [new_list_element]\n","        map_with_list_as_value[map_key] = new_list\n","    \n","    def append_to_set(map_with_set_as_value, map_key, new_set_element):\n","        existing_set = map_with_set_as_value.get(map_key, set())\n","        existing_set.add(new_set_element)\n","        map_with_set_as_value[map_key] = existing_set"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ppXuS0nrTz7r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class QuestionRelevance:\n","    \"\"\"\n","        Makes no distinction between \n","        PerfectMatch and Relevant questions\n","    \"\"\"\n","    \n","    INT_RELEVANT = 1\n","    RELEVANT = \"Relevant\"\n","    \n","    PERFECT_MACH = \"PerfectMatch\"\n","    \n","    INT_IRRELEVANT = 0\n","    IRRELEVANT = \"Irrelevant\"\n","    \n","    \n","    def to_number(string_relevance):\n","        return QuestionRelevance.INT_IRRELEVANT\\\n","            if string_relevance == QuestionRelevance.IRRELEVANT \\\n","            else QuestionRelevance.INT_RELEVANT\n","    \n","    \n","    def from_number(int_relevance):\n","        return QuestionRelevance.IRRIELEVANT \\\n","            if string_relevance == QuestionRelevance.INT_IRRELEVANT \\\n","            else QuestionRelevance.RELEVANT"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZlHsLtZ7T2DB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Thread:\n","    \n","    def __init__(self, question, rel_questions):\n","        self.question = question\n","        self.rel_questions = rel_questions\n","\n","    def __str__(self):\n","        return self.question.__str__()\n","    \n","    def __repr__(self):\n","        return self.question.__repr__()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"thBv8xLrUprr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class ThreadCollection:\n","    \n","    def __init__(self):\n","        self.by_topic = {}\n","    \n","    def add(self, string_topic, thread):\n","        MapHelper.append_to_list(self.by_topic, string_topic, thread)\n","    \n","    def get(self, string_topic):\n","        return self.by_topic.get(string_topic, [])\n","    \n","    def topics(self):\n","        return list(self.by_topic.keys())\n","\n","    def topic_thread_pairs(self):\n","        return self.by_topic.items()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TbDdhp83UqHd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from collections import namedtuple\n","\n","\n","class QuestionData:\n","  \n","    STRING_ID_KEY = \"ORGQ_ID\"\n","    \n","    def __init__(self, id, subject, body):\n","        self.id = id\n","        self.subject = subject\n","        self.body = body\n","    \n","    def __str__(self):\n","        return str(self.body)\n","    \n","    def __repr__(self):\n","        return self.__str__()\n","        \n","        \n","class RelQuestionData:\n","    \n","    STRING_RELEVANCE_KEY = \"RELQ_RELEVANCE2ORGQ\"\n","    STRING_USERNAME_KEY = \"RELQ_USERNAME\"\n","    STRING_DATE_KEY = \"RELQ_DATE\"\n","    STRING_ID_KEY = \"RELQ_ID\"\n","    \n","    def __init__(self, metadata, subject, body):\n","        self.metadata = metadata\n","        self.subject = subject\n","        self.body = body\n","        \n","    def __str__(self):\n","        return str(self.body)\n","    \n","    def __repr__(self):\n","        return self.__str__()\n","\n","    \n","class Metadata:\n","    \n","    def __init__(self, id, user, date, relevance):\n","        self.id = id\n","        self.user = user\n","        self.date = date\n","        self.relevance = relevance\n","    \n","    \n","QuestionQuestionPair = namedtuple('QuestionQuestionPair', ['question', 'rel_question', 'data'])\n","\n","# set data to None by default\n","QuestionQuestionPair.__new__.__defaults__ = (None,)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hMod7WxpUqQh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def to_question_data(node_question):\n","    subject = node_question[0]\n","    body = node_question[1]\n","    \n","    return QuestionData(node_question.attrib[QuestionData.STRING_ID_KEY], subject.text, body.text)\n","\n","\n","def to_rel_question_data(node_rel_questions):\n","    f = lambda node: RelQuestionData(Metadata(node.attrib[RelQuestionData.STRING_ID_KEY],\n","                                         node.attrib[RelQuestionData.STRING_USERNAME_KEY],\n","                                         node.attrib[RelQuestionData.STRING_DATE_KEY],\n","                                         QuestionRelevance.to_number(node.attrib[RelQuestionData.STRING_RELEVANCE_KEY])), \n","                                node[0].text, node[1].text)\n","    \n","    return [f(node) for node in node_rel_questions if node[1].text is not None]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YQQMzd-WUqOi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from nltk.corpus.reader import XMLCorpusReader, XMLCorpusView\n","\n","def load_data(string_basedir, string_filenames_in_basedir):\n","    \n","    for string_filename in string_filenames_in_basedir:\n","        corpus_reader = XMLCorpusReader(string_basedir, string_filename)\n","        i = 0\n","        node_rel_questions = []\n","        for root_node in corpus_reader.xml():\n","            node_question = root_node\n","            node_rel_questions.append(root_node[2][0])\n","            i += 1\n","            if i == 10:\n","                thread_question = to_question_data(node_question)\n","                thread_rel_questions = to_rel_question_data(node_rel_questions)\n","\n","                thread = Thread(thread_question, thread_rel_questions)        \n","                string_topic = \"\"\n","                \n","                i = 0\n","                node_rel_questions = []\n","            \n","                yield string_topic, thread"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3jTN5IzBUqMd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from itertools import *\n","\n","\n","def get_limited_generator(string_basedir,\n","                          list_string_filenames_in_basedir,\n","                          start_index_inclusive, \n","                          end_index_exclusive = None, \n","                          step = None):\n","    data_generator = load_data(string_basedir, list_string_filenames_in_basedir)\n","    return islice(data_generator, start_index_inclusive, end_index_exclusive, step)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AEr2Aen1UqKt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def repeat_relevant(question, list_relevant, int_how_many):\n","    for i in range(int_how_many):\n","        question = QuestionData(str(question.subject), str(question.body))\n","        yield QuestionQuestionPair(question, list_relevant[i % len(list_relevant)] )\n","    \n","\n","def get_data(data_generator, do_repeat_relevant = False):\n","    X = []\n","    y = []\n","    \n","    for topic, thread in data_generator:\n","        question = thread.question\n","        list_relevant = []\n","        \n","        for rel_question in thread.rel_questions:\n","            question = QuestionData(str(question.id), str(question.subject), str(question.body))\n","            question_question_pair = QuestionQuestionPair(question, rel_question)\n","            \n","            X += [ question_question_pair ]\n","            y += [ rel_question.metadata.relevance ]\n","    \n","            if rel_question.metadata.relevance == QuestionRelevance.INT_RELEVANT:\n","                list_relevant += [rel_question]\n","        \n","        num_relevant = len(list_relevant)\n","        num_irrelevant = len(thread.rel_questions) - num_relevant\n","        \n","        if num_relevant < num_irrelevant \\\n","            and do_repeat_relevant \\\n","            and num_relevant != 0:\n","                \n","            delta = num_irrelevant - num_relevant\n","            \n","            X += repeat_relevant(question, list_relevant, delta)\n","            y += [ QuestionRelevance.INT_RELEVANT for i in range(delta) ]\n","        \n","    return X, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DY5ww8lFOI1g","colab_type":"text"},"cell_type":"markdown","source":["##dataset loading"]},{"metadata":{"id":"YSRAW1lXU7y-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_generator = get_limited_generator(train_dir, ['SemEval2016-Task3-CQA-QL-train-part1.xml', 'SemEval2016-Task3-CQA-QL-train-part2.xml'], \n","                                       0, None, None)\n","\n","dev_generator = get_limited_generator(dev_dir, ['SemEval2016-Task3-CQA-QL-dev.xml'], 0, None, None)\n","test_generator = get_limited_generator(test_dir, ['SemEval2017-task3-English-test.xml'], 0, None, None)\n","#test_generator_A = get_limited_generator(test_dir, ['SemEval2017-task3-English-test-subtaskA.xml'], 0, None, None, subtask_A=True)\n","\n","X = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","y = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","\n","X[\"train\"], y[\"train\"] = get_data(train_generator, do_repeat_relevant=False)\n","X[\"dev\"], y[\"dev\"] = get_data(dev_generator, do_repeat_relevant=False)\n","X[\"test\"], y[\"test\"] = get_data(test_generator, do_repeat_relevant=False)\n","#X[\"test_A\"], y[\"test_A\"] = get_data(test_generator_A, do_repeat_relevant=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L3yz0UoMU7tj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":285},"outputId":"b6f361bc-dcfa-46ef-870b-c9cb8ecae400","executionInfo":{"status":"ok","timestamp":1528742447169,"user_tz":-120,"elapsed":479,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["key = \"test\"\n","print(len(X[key]))\n","print(len(y[key]))\n","for i in range(5):\n","  x = X[key][i]\n","  print(x[0].id + \" \" + x[0].subject + \" \" + x[0].body)\n","  print(x[1].metadata.id + \" \" + x[1].subject + \" \" + x[1].body)\n","#print(X[0][0])\n","print(type(y[key]))\n","print(y[key][:5])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["880\n","880\n","Q388 HOW TO APPLY AND OBTAIN VISAS TO UK AND SPAIN Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We are bona fide residents in Qatar by the way. Thank you\n","Q388_R14 Schengen Visa @ Greece Embassy Do you know how long it will take to get Schengen Visa from Embassy of Greece? 3 days? 1 week? any idea? Thanks.\n","Q388 HOW TO APPLY AND OBTAIN VISAS TO UK AND SPAIN Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We are bona fide residents in Qatar by the way. Thank you\n","Q388_R21 HELLLLPPPP! Now that I have your attention (good morning btw ;)... Does anyone know if transit visa's are issued here?\n","Q388 HOW TO APPLY AND OBTAIN VISAS TO UK AND SPAIN Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We are bona fide residents in Qatar by the way. Thank you\n","Q388_R23 Swiss embassy Hi there. Can anyone tell me if there is a Swiss embassy in Doha ? If so , where is it ? Thanks\n","Q388 HOW TO APPLY AND OBTAIN VISAS TO UK AND SPAIN Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We are bona fide residents in Qatar by the way. Thank you\n","Q388_R24 Worst Embassy in Qatar? Ok - your nominations please for the \"Most Useless Embassy\" in Qatar? Who should have their little diplomatic flag stuffed up their nostril? Who forgets who pays their salaries to swan around to cocktail parties? Who couldn't get care less about the citizens as long as they get to have a shiny car? Who thinks a visa is a card to go shopping with? Please Give me reasons.... no more than 300 words ... thanks a bundle.\n","Q388 HOW TO APPLY AND OBTAIN VISAS TO UK AND SPAIN Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We are bona fide residents in Qatar by the way. Thank you\n","Q388_R28 Coming to doha next week - need tourist visa! Hi there, I am coming to doha on Thursday and I know I will need a tourist visa. Someone mentioned that I get it at the airport for 55riyals, is this correct? I saw on the Qatar Government website that you needed evidence of which hotel you would be staying in? But I am staying with friends during my stay? Any advice would be good as I am quite nervous about flying alone and dont want any problems when I arrive! Thanks, Beth :-)\n","<class 'list'>\n","[0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"metadata":{"id":"dNLkWuqc9RnY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"6b1038f8-d059-463f-f555-94413142e48b","executionInfo":{"status":"ok","timestamp":1528742448616,"user_tz":-120,"elapsed":1233,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["questions = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","answers = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","for key in X.keys():\n","  for x in X[key]:\n","    questions[key].append(x[0].body)\n","    answers[key].append(x[1].body)\n","  \n","#print(questions[:5])\n","#print(answers[:5])\n","\n","tokenizer = Tokenizer(lower=True)\n","tokenizer.fit_on_texts(questions[\"train\"] + answers[\"train\"])\n","vocab_size = len(tokenizer.word_index)\n","print('Found %s unique tokens.' % vocab_size)\n","\n","quest = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","answ = {\"train\": [], \"dev\":[], \"test\":[], \"test_A\":[]}\n","\n","# integer encode the sentences\n","for key in questions.keys():\n","  quest[key] = tokenizer.texts_to_sequences(questions[key])\n","  \n","for key in answers.keys():\n","  answ[key] = tokenizer.texts_to_sequences(answers[key])\n","\n","# prepare data for Keras network\n","MAX_SEQUENCE_LENGTH = 100\n","\n","train_X = [pad_sequences(quest[\"train\"], maxlen=MAX_SEQUENCE_LENGTH), pad_sequences(answ[\"train\"], maxlen=MAX_SEQUENCE_LENGTH)]\n","dev_X = [pad_sequences(quest[\"dev\"], maxlen=MAX_SEQUENCE_LENGTH), pad_sequences(answ[\"dev\"], maxlen=MAX_SEQUENCE_LENGTH)]\n","test_X = [pad_sequences(quest[\"test\"], maxlen=MAX_SEQUENCE_LENGTH), pad_sequences(answ[\"test\"], maxlen=MAX_SEQUENCE_LENGTH)]\n","#test_A_X = [pad_sequences(quest[\"test_A\"], maxlen=MAX_SEQUENCE_LENGTH), pad_sequences(answ[\"test_A\"], maxlen=MAX_SEQUENCE_LENGTH)]\n","\n","train_y = np.array(y[\"train\"])\n","dev_y = np.array(y[\"dev\"])\n","test_y = np.array(y[\"test\"])\n","#test_A_y = np.array(y[\"test_A\"])\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Found 7980 unique tokens.\n"],"name":"stdout"}]},{"metadata":{"id":"5-36nmDRabjY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":441},"outputId":"177b8989-a7dc-42e6-e802-48d53a59c171","executionInfo":{"status":"ok","timestamp":1528742449831,"user_tz":-120,"elapsed":998,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["print(test_X[0][:3])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0   11  108  168\n","     5 1104   21  811   35    2 1235  585    8   67  763    2   68   26\n","   801    2    3  214    6 4488   46   18 1345    4   15   88    3  252\n","    87   14]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0   11  108  168\n","     5 1104   21  811   35    2 1235  585    8   67  763    2   68   26\n","   801    2    3  214    6 4488   46   18 1345    4   15   88    3  252\n","    87   14]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0   11  108  168\n","     5 1104   21  811   35    2 1235  585    8   67  763    2   68   26\n","   801    2    3  214    6 4488   46   18 1345    4   15   88    3  252\n","    87   14]]\n"],"name":"stdout"}]},{"metadata":{"id":"DTr_4aAmZway","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"43e277a6-fb06-41a2-9bb9-fc95a5bd52a6","executionInfo":{"status":"ok","timestamp":1528742450591,"user_tz":-120,"elapsed":606,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["maxlen = 100\n","\n","train_lens = [np.count_nonzero(t) for t in answ[\"train\"] + quest[\"train\"]]\n","x = len(train_lens)\n","sx = len([l for l in train_lens if l > maxlen])\n","print(\"Train sentences longer than {} tokens: {:.2f} %\".format(maxlen,sx/x*100))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Train sentences longer than 100 tokens: 0.00 %\n"],"name":"stdout"}]},{"metadata":{"id":"yKA3iT8qTt-G","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1273},"outputId":"189327f9-4b5b-4e1b-9296-606d8d25b72e","executionInfo":{"status":"ok","timestamp":1528742451374,"user_tz":-120,"elapsed":546,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["print(train_X[0][:5])\n","print(train_X[1][:5])\n","print(train_y[:5])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0  53   1  11 110  63 733   8 856]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0  53   1  11 110  63 733   8 856]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0  53   1  11 110  63 733   8 856]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0  53   1  11 110  63 733   8 856]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0  53   1  11 110  63 733   8 856]]\n","[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    7   24   17  103    1   11   79 4917  856 2954\n","     4   15]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    43   11   17   50   81   12    5  103   53    1   11   16    5   63\n","   856 4918 4919  786    1  177    5  856    4 4920 4921   48 2955   12\n","  4922    8 3812 1713 2747   13    7 3269 1392  197   99   12   20 3270\n","    17 4923]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0   81   12   53    7    3   80  103\n","     2   68    8    5  856  491   14    1  166   59    2  497 2748    8\n","    13  122   38  166  126  105   29  486   22 3813 3814   37   13 3271\n","   270  292]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0   43   24    1   11  187\n","     5  454   10  856  376   41   33    1  188   73   50    7  268   11\n","   108   58   12   73  856  376    7   63    6   35   74   31   13  157\n","    12   36]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0   19 4924\n","    14  135]]\n","[1 1 0 1 0]\n"],"name":"stdout"}]},{"metadata":{"id":"u17QA4HCOBZl","colab_type":"text"},"cell_type":"markdown","source":["##gloVe"]},{"metadata":{"id":"krNF5hVZW-B-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":52},"outputId":"bde7d394-b214-402f-d130-6f843048cdc9","executionInfo":{"status":"ok","timestamp":1528742482956,"user_tz":-120,"elapsed":31301,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["# load the whole embedding into memory\n","embeddings_index = dict()\n","f = open('glove/glove.6B.300d.txt')\n","for line in f:\n","\tvalues = line.split()\n","\tword = values[0]\n","\tcoefs = np.asarray(values[1:], dtype='float32')\n","\tembeddings_index[word] = coefs\n","f.close()\n","print('Loaded %s word vectors.' % len(embeddings_index))\n","\n","# create a weight matrix for words in training docs\n","embedding_matrix = np.zeros((vocab_size+1, 300))\n","for word, i in tokenizer.word_index.items():\n","\tembedding_vector = embeddings_index.get(word)\n","\tif embedding_vector is not None:\n","\t\tembedding_matrix[i] = embedding_vector\n","    \n","print('Embedding matrix shape=', embedding_matrix.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Loaded 400000 word vectors.\n","Embedding matrix shape= (7981, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"U_xDop7O9ra6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"e4a8cd4c-b98a-4a95-a9eb-594f0d24715a","executionInfo":{"status":"ok","timestamp":1528742483719,"user_tz":-120,"elapsed":499,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["device_name = tensorflow.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","def myLSTM(*args, **kwargs):\n","  if device_name == '/device:GPU:0':\n","    return CuDNNLSTM(*args, **kwargs)\n","  return LSTM(*args, **kwargs)\n","\n","def myGRU(*args, **kwargs):\n","  if device_name == '/device:GPU:0':\n","    return CuDNNGRU(*args, **kwargs)\n","  return GRU(*args, **kwargs)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"YSaEdmXNd3JA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir checkpoints"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5MWUr1nZOgGB","colab_type":"text"},"cell_type":"markdown","source":["##evaluation"]},{"metadata":{"id":"I4PVc7UxvqLN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def predict(model, inputs, batch_size):\n","    probs = model.predict(inputs, batch_size=batch_size)\n","    return np.squeeze(probs), np.array([\"false\" if x < 0.5 else \"true\" for x in probs])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ljCpaqWo0s7H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir preds"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FfmKfbDBmI3W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def create_pred_file(probs, preds, X, pred_filepath):\n","    with open(pred_filepath, 'w') as pred_file:\n","        for i in range(len(X)):\n","            x = X[i]\n","            print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(x[0].id, x[1].metadata.id, 0, probs[i], preds[i]), \n","                  file=pred_file)\n","    files.download(pred_filepath)\n","    \n","\n","def predict_and_save(model, processed_input, unprocessed_input, pred_filepath):\n","    probs, preds = predict(model, processed_input, BATCH_SIZE)\n","    create_pred_file(probs, preds, unprocessed_input, pred_filepath)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r8pBwEvHCbs_","colab_type":"text"},"cell_type":"markdown","source":["##final CNN model"]},{"metadata":{"id":"nqXVzjSFCcPZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1331},"outputId":"3a699cb5-7a6a-4d63-911b-7c677956e10c","executionInfo":{"status":"ok","timestamp":1528645321455,"user_tz":-120,"elapsed":7899,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["#\n","# CNN classifer\n","#\n","from keras.optimizers import *\n","sgd = SGD(lr=0.1, momentum=0.1, decay=0.99, nesterov=True)\n","#adagrad = Adagrad(lr=0.5, epsilon=None, decay=0.09)\n","activation = 'elu'\n","padding = 'valid'\n","filters = 300\n","kernel_size = 3\n","\n","HIDDEN = 300\n","\n","print('Build model...')\n","inputs_q = Input(shape=(MAX_SEQUENCE_LENGTH,), name='question')\n","inputs_a = Input(shape=(MAX_SEQUENCE_LENGTH,), name='answer')\n","\n","# add masking\n","mask = Masking(mask_value=0., name='masking')\n","inputs_q_ = mask(inputs_q)\n","inputs_a_ = mask(inputs_a)\n","\n","embed = Embedding(vocab_size+1, HIDDEN, weights=[embedding_matrix], trainable=False, mask_zero=False, name='embedding')#mask_zero=True,trainable=False\n","embed_q = embed(inputs_q_)\n","embed_a = embed(inputs_a_)\n","\n","# convolution one\n","conv1 = Conv1D(filters, kernel_size, name='conv1', padding='valid', activation=activation, strides=1)\n","conv1_q = conv1(embed_q)\n","conv1_a = conv1(embed_a)\n","\n","pool1 = GlobalMaxPooling1D(name='pool1') #MAX\n","pool1_q = pool1(conv1_q)\n","pool1_a = pool1(conv1_a)\n","\n","# convolution two\n","conv2 = Conv1D(filters, kernel_size, name='conv2', padding='valid', activation=activation, strides=1)\n","conv2_q = conv2(conv1_q)\n","conv2_a = conv2(conv1_a)\n","\n","pool2 = GlobalMaxPooling1D(name='pool2') #MAX\n","pool2_q = pool2(conv2_q)\n","pool2_a = pool2(conv2_a)\n","\n","# convolution three\n","conv3 = Conv1D(filters, kernel_size, name='conv3', padding='valid', activation=activation, strides=1)\n","conv3_q = conv1(conv2_q)\n","conv3_a = conv1(conv2_a)\n","\n","pool3 = GlobalMaxPooling1D(name='pool3')\n","pool3_q = pool1(conv3_q)\n","pool3_a = pool1(conv3_a)\n","\n","# convolution four\n","conv4 = Conv1D(filters, kernel_size, name='conv4', padding='valid', activation=activation, strides=1)\n","conv4_q = conv1(conv3_q)\n","conv4_a = conv1(conv3_a)\n","\n","pool4 = GlobalMaxPooling1D(name='pool4')\n","pool4_q = pool1(conv4_q)\n","pool4_a = pool1(conv4_a)\n","\n","# concatenations\n","q_ = concatenate([pool1_q, pool2_q], name='question_concat') #, pool3_q, pool4_q\n","a_ = concatenate([pool1_a, pool2_a], name='answer_concat') #, pool3_a, pool4_a\n","#re_q = Reshape((-1, HIDDEN))(q_)\n","#re_a = Reshape((-1, HIDDEN))(a_)\n","q = Dropout(rate=0.25, name='question_dropout')(q_)\n","a = Dropout(rate=0.25, name='answer_dropout')(a_)\n","\n","#outs = Lambda(euclidean_similarity, name='euclid_similarity')([q,a])\n","#outs = Dot(axes=-1, normalize=True)([q,a])\n","\n","qa_mul = multiply([q, a], name='multiply') \n","qa_sub = subtract([q, a], name='subtract')\n","qa_max = maximum([q, a], name='maximum')\n","qa_avg = average([q, a], name='average')\n","concat = concatenate([q, a, qa_max, qa_mul, qa_sub, qa_avg], name='final_concat')\n","\n","# attention block - multi-dimensional self-attention\n","reshaped = Reshape((-1, HIDDEN))(concat)\n","compatibilities = Dense(HIDDEN, activation='elu', use_bias=False, name='compatibilites')(reshaped)\n","attention_weights = Dense(HIDDEN, activation='softmax', use_bias=False, name='self_att_weights')(compatibilities)\n","attention_ = multiply([reshaped, attention_weights], name='attention_mul')\n","attention = Lambda(lambda x: K.sum(x, axis=1), name=\"attention\")(attention_)\n","#attention = dot([reshaped, attention_weights], axes=-1, name='attention')\n","\n","hidden_ = Dense(HIDDEN, activation='tanh', name='final_dense_1')(attention)\n","#hidden_2 = Dense(HIDDEN, activation='elu', name='final_dense_2')(hidden_1)\n","#hidden_ = Dropout(rate=0.25, name=\"hidden_dropout\")(hidden_2)\n","#hidden = BatchNormalization()(hidden_)\n","\n","preds = Dense(1, activation='sigmoid', name='predictions')(attention)#(hidden_)\n","\n","CNN = Model(inputs=[inputs_q, inputs_a], outputs=[preds])\n","# try using different optimizers and different optimizer configs\n","CNN.compile(loss='binary_crossentropy',\n","              optimizer='adam',#'adadelta',\n","              metrics=['accuracy']) # add mean_average_precision ?\n","print(CNN.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build model...\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","question (InputLayer)           (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","answer (InputLayer)             (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","masking (Masking)               (None, 100)          0           question[0][0]                   \n","                                                                 answer[0][0]                     \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 100, 300)     2394300     masking[0][0]                    \n","                                                                 masking[1][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv1D)                  multiple             270300      embedding[0][0]                  \n","                                                                 embedding[1][0]                  \n","__________________________________________________________________________________________________\n","conv2 (Conv1D)                  (None, 96, 300)      270300      conv1[0][0]                      \n","                                                                 conv1[1][0]                      \n","__________________________________________________________________________________________________\n","pool1 (GlobalMaxPooling1D)      (None, 300)          0           conv1[0][0]                      \n","                                                                 conv1[1][0]                      \n","__________________________________________________________________________________________________\n","pool2 (GlobalMaxPooling1D)      (None, 300)          0           conv2[0][0]                      \n","                                                                 conv2[1][0]                      \n","__________________________________________________________________________________________________\n","question_concat (Concatenate)   (None, 600)          0           pool1[0][0]                      \n","                                                                 pool2[0][0]                      \n","__________________________________________________________________________________________________\n","answer_concat (Concatenate)     (None, 600)          0           pool1[1][0]                      \n","                                                                 pool2[1][0]                      \n","__________________________________________________________________________________________________\n","question_dropout (Dropout)      (None, 600)          0           question_concat[0][0]            \n","__________________________________________________________________________________________________\n","answer_dropout (Dropout)        (None, 600)          0           answer_concat[0][0]              \n","__________________________________________________________________________________________________\n","maximum (Maximum)               (None, 600)          0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 600)          0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","subtract (Subtract)             (None, 600)          0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","average (Average)               (None, 600)          0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","final_concat (Concatenate)      (None, 3600)         0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","                                                                 maximum[0][0]                    \n","                                                                 multiply[0][0]                   \n","                                                                 subtract[0][0]                   \n","                                                                 average[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_82 (Reshape)            (None, 12, 300)      0           final_concat[0][0]               \n","__________________________________________________________________________________________________\n","compatibilites (Dense)          (None, 12, 300)      90000       reshape_82[0][0]                 \n","__________________________________________________________________________________________________\n","self_att_weights (Dense)        (None, 12, 300)      90000       compatibilites[0][0]             \n","__________________________________________________________________________________________________\n","attention_mul (Multiply)        (None, 12, 300)      0           reshape_82[0][0]                 \n","                                                                 self_att_weights[0][0]           \n","__________________________________________________________________________________________________\n","attention (Lambda)              (None, 300)          0           attention_mul[0][0]              \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 1)            301         attention[0][0]                  \n","==================================================================================================\n","Total params: 3,115,201\n","Trainable params: 720,901\n","Non-trainable params: 2,394,300\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"9LZlgo8KCeIb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1187},"outputId":"39e8a176-f53a-4a74-c2d2-31f7b46a231e","executionInfo":{"status":"ok","timestamp":1528645402069,"user_tz":-120,"elapsed":80517,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["BATCH_SIZE = 32 # set to max allowable value\n","EPOCHS = 10*3#10*2\n","\n","print('Train...')\n","CNN.fit(train_X, train_y,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_data=(dev_X, dev_y),\n","          verbose=2,\n","          callbacks=None)\n","\n","score, acc = CNN.evaluate(test_X, test_y, batch_size=BATCH_SIZE)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n","# save model\n","CNN.save('cnn_maxpool_final_B.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train...\n","Train on 2593 samples, validate on 495 samples\n","Epoch 1/30\n"," - 8s - loss: 0.6767 - acc: 0.5927 - val_loss: 0.6864 - val_acc: 0.5717\n","Epoch 2/30\n"," - 2s - loss: 0.6624 - acc: 0.5981 - val_loss: 0.6896 - val_acc: 0.5717\n","Epoch 3/30\n"," - 2s - loss: 0.6626 - acc: 0.5989 - val_loss: 0.6795 - val_acc: 0.5737\n","Epoch 4/30\n"," - 2s - loss: 0.6385 - acc: 0.6332 - val_loss: 0.6882 - val_acc: 0.5778\n","Epoch 5/30\n"," - 2s - loss: 0.6226 - acc: 0.6475 - val_loss: 0.6803 - val_acc: 0.5798\n","Epoch 6/30\n"," - 2s - loss: 0.5950 - acc: 0.6653 - val_loss: 0.7260 - val_acc: 0.5657\n","Epoch 7/30\n"," - 2s - loss: 0.5764 - acc: 0.7015 - val_loss: 0.7196 - val_acc: 0.6081\n","Epoch 8/30\n"," - 2s - loss: 0.5612 - acc: 0.7162 - val_loss: 0.7384 - val_acc: 0.5960\n","Epoch 9/30\n"," - 2s - loss: 0.5500 - acc: 0.7189 - val_loss: 0.7456 - val_acc: 0.5859\n","Epoch 10/30\n"," - 2s - loss: 0.5188 - acc: 0.7501 - val_loss: 0.7586 - val_acc: 0.5960\n","Epoch 11/30\n"," - 2s - loss: 0.5233 - acc: 0.7366 - val_loss: 0.8153 - val_acc: 0.5636\n","Epoch 12/30\n"," - 2s - loss: 0.5162 - acc: 0.7362 - val_loss: 0.6702 - val_acc: 0.5919\n","Epoch 13/30\n"," - 2s - loss: 0.5431 - acc: 0.7293 - val_loss: 0.6740 - val_acc: 0.5899\n","Epoch 14/30\n"," - 2s - loss: 0.5340 - acc: 0.7316 - val_loss: 0.6683 - val_acc: 0.5939\n","Epoch 15/30\n"," - 2s - loss: 0.5241 - acc: 0.7281 - val_loss: 0.7135 - val_acc: 0.5879\n","Epoch 16/30\n"," - 2s - loss: 0.5151 - acc: 0.7466 - val_loss: 0.7766 - val_acc: 0.5838\n","Epoch 17/30\n"," - 2s - loss: 0.5078 - acc: 0.7513 - val_loss: 0.7378 - val_acc: 0.5939\n","Epoch 18/30\n"," - 2s - loss: 0.5033 - acc: 0.7486 - val_loss: 0.7698 - val_acc: 0.5758\n","Epoch 19/30\n"," - 2s - loss: 0.4860 - acc: 0.7524 - val_loss: 0.7769 - val_acc: 0.5939\n","Epoch 20/30\n"," - 2s - loss: 0.4724 - acc: 0.7644 - val_loss: 0.8463 - val_acc: 0.5717\n","Epoch 21/30\n"," - 2s - loss: 0.4730 - acc: 0.7705 - val_loss: 0.8018 - val_acc: 0.5636\n","Epoch 22/30\n"," - 2s - loss: 0.4535 - acc: 0.7759 - val_loss: 0.8486 - val_acc: 0.5778\n","Epoch 23/30\n"," - 2s - loss: 0.4650 - acc: 0.7651 - val_loss: 0.8679 - val_acc: 0.5818\n","Epoch 24/30\n"," - 2s - loss: 0.4617 - acc: 0.7767 - val_loss: 0.8359 - val_acc: 0.5838\n","Epoch 25/30\n"," - 2s - loss: 0.4516 - acc: 0.7829 - val_loss: 0.8684 - val_acc: 0.5293\n","Epoch 26/30\n"," - 2s - loss: 0.4629 - acc: 0.7721 - val_loss: 0.8900 - val_acc: 0.5455\n","Epoch 27/30\n"," - 2s - loss: 0.4634 - acc: 0.7694 - val_loss: 0.8764 - val_acc: 0.5657\n","Epoch 28/30\n"," - 2s - loss: 0.4847 - acc: 0.7563 - val_loss: 0.8140 - val_acc: 0.5717\n","Epoch 29/30\n"," - 2s - loss: 0.4528 - acc: 0.7813 - val_loss: 0.8204 - val_acc: 0.5677\n","Epoch 30/30\n"," - 2s - loss: 0.4480 - acc: 0.7921 - val_loss: 0.8723 - val_acc: 0.5455\n","880/880 [==============================] - 0s 298us/step\n","Test score: 0.7582295461134477\n","Test accuracy: 0.5227272727272727\n"],"name":"stdout"}]},{"metadata":{"id":"7e9l7AlDpQoV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_and_save(CNN, test_X, X[\"test\"], \"preds/cnn_maxpool_final_B.pred\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UATjCkJVCpsq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["files.download('cnn_maxpool_final_B.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"etSCxrdfCq8l","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1619},"outputId":"c78f94ef-7d6a-46a5-910d-f08c91d529c6","executionInfo":{"status":"ok","timestamp":1528645433516,"user_tz":-120,"elapsed":8294,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["#\n","# CNN classifer average pooling\n","#\n","from keras.optimizers import *\n","sgd = SGD(lr=0.1, momentum=0.1, decay=0.99, nesterov=True)\n","#adagrad = Adagrad(lr=0.5, epsilon=None, decay=0.09)\n","activation = 'elu'\n","padding = 'valid'\n","filters = 300\n","kernel_size = 3\n","\n","HIDDEN = 300\n","\n","print('Build model...')\n","inputs_q = Input(shape=(MAX_SEQUENCE_LENGTH,), name='question')\n","inputs_a = Input(shape=(MAX_SEQUENCE_LENGTH,), name='answer')\n","\n","# add masking\n","mask = Masking(mask_value=0., name='masking')\n","inputs_q_ = mask(inputs_q)\n","inputs_a_ = mask(inputs_a)\n","\n","embed = Embedding(vocab_size+1, HIDDEN, weights=[embedding_matrix], trainable=False, mask_zero=False, name='embedding')#mask_zero=True,trainable=False\n","embed_q = embed(inputs_q_)\n","embed_a = embed(inputs_a_)\n","\n","# convolution one\n","conv1 = Conv1D(filters, kernel_size, name='conv1', padding='valid', activation=activation, strides=1)\n","conv1_q = conv1(embed_q)\n","conv1_a = conv1(embed_a)\n","\n","pool1 = GlobalAveragePooling1D(name='pool1')\n","pool1_q = pool1(conv1_q)\n","pool1_a = pool1(conv1_a)\n","\n","# convolution two\n","conv2 = Conv1D(filters, kernel_size, name='conv2', padding='valid', activation=activation, strides=1)\n","conv2_q = conv2(conv1_q)\n","conv2_a = conv2(conv1_a)\n","\n","pool2 = GlobalAveragePooling1D(name='pool2')\n","pool2_q = pool2(conv2_q)\n","pool2_a = pool2(conv2_a)\n","\n","# convolution three\n","conv3 = Conv1D(filters, kernel_size, name='conv3', padding='valid', activation=activation, strides=1)\n","conv3_q = conv1(conv2_q)\n","conv3_a = conv1(conv2_a)\n","\n","pool3 = GlobalAveragePooling1D(name='pool3')\n","pool3_q = pool1(conv3_q)\n","pool3_a = pool1(conv3_a)\n","\n","# convolution four\n","conv4 = Conv1D(filters, kernel_size, name='conv4', padding='valid', activation=activation, strides=1)\n","conv4_q = conv1(conv3_q)\n","conv4_a = conv1(conv3_a)\n","\n","pool4 = GlobalAveragePooling1D(name='pool4')\n","pool4_q = pool1(conv4_q)\n","pool4_a = pool1(conv4_a)\n","\n","# concatenations\n","q_ = concatenate([pool1_q, pool2_q, pool3_q, pool4_q], name='question_concat')\n","a_ = concatenate([pool1_a, pool2_a, pool3_a, pool4_a], name='answer_concat')\n","re_q = Reshape((-1, HIDDEN))(q_)\n","re_a = Reshape((-1, HIDDEN))(a_)\n","q = Dropout(rate=0.25, name='question_dropout')(re_q)#(q_)\n","a = Dropout(rate=0.25, name='answer_dropout')(re_a)#(a_)\n","\n","qa_mul = multiply([q, a], name='multiply') \n","qa_sub = subtract([q, a], name='subtract')\n","qa_max = maximum([q, a], name='maximum')\n","qa_avg = average([q, a], name='average')\n","concat = concatenate([q, a, qa_max, qa_mul, qa_sub, qa_avg], name='final_concat')\n","\n","# attention block - multi-dimensional self-attention\n","reshaped = Reshape((-1, HIDDEN))(concat)\n","compatibilities = Dense(HIDDEN, activation='elu', use_bias=False, name='compatibilites')(reshaped)\n","attention_weights = Dense(HIDDEN, activation='softmax', use_bias=False, name='self_att_weights')(compatibilities)\n","attention_ = multiply([reshaped, attention_weights], name='attention_mul')\n","attention = Lambda(lambda x: K.sum(x, axis=1), name=\"attention\")(attention_)\n","#attention = dot([reshaped, attention_weights], axes=-1, name='attention')\n","\n","hidden_ = Dense(HIDDEN, activation='tanh', name='final_dense_1')(attention)\n","#hidden_2 = Dense(HIDDEN, activation='elu', name='final_dense_2')(hidden_1)\n","#hidden_ = Dropout(rate=0.25, name=\"hidden_dropout\")(hidden_2)\n","#hidden = BatchNormalization()(hidden_)\n","\n","preds = Dense(1, activation='sigmoid', name='predictions')(attention)#(hidden_)\n","\n","CNN1 = Model(inputs=[inputs_q, inputs_a], outputs=[preds])\n","# try using different optimizers and different optimizer configs\n","CNN1.compile(loss='binary_crossentropy',\n","              optimizer='adam',#'adadelta',\n","              metrics=['accuracy']) # add mean_average_precision ?\n","print(CNN1.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build model...\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","question (InputLayer)           (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","masking (Masking)               (None, 100)          0           question[0][0]                   \n","                                                                 answer[0][0]                     \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 100, 300)     2394300     masking[0][0]                    \n","                                                                 masking[1][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv1D)                  multiple             270300      embedding[0][0]                  \n","                                                                 embedding[1][0]                  \n","                                                                 conv2[0][0]                      \n","                                                                 conv2[1][0]                      \n","                                                                 conv1[2][0]                      \n","                                                                 conv1[3][0]                      \n","__________________________________________________________________________________________________\n","answer (InputLayer)             (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","conv2 (Conv1D)                  (None, 96, 300)      270300      conv1[0][0]                      \n","                                                                 conv1[1][0]                      \n","__________________________________________________________________________________________________\n","pool1 (GlobalAveragePooling1D)  (None, 300)          0           conv1[0][0]                      \n","                                                                 conv1[1][0]                      \n","                                                                 conv1[2][0]                      \n","                                                                 conv1[3][0]                      \n","                                                                 conv1[4][0]                      \n","                                                                 conv1[5][0]                      \n","__________________________________________________________________________________________________\n","pool2 (GlobalAveragePooling1D)  (None, 300)          0           conv2[0][0]                      \n","                                                                 conv2[1][0]                      \n","__________________________________________________________________________________________________\n","question_concat (Concatenate)   (None, 1200)         0           pool1[0][0]                      \n","                                                                 pool2[0][0]                      \n","                                                                 pool1[2][0]                      \n","                                                                 pool1[4][0]                      \n","__________________________________________________________________________________________________\n","answer_concat (Concatenate)     (None, 1200)         0           pool1[1][0]                      \n","                                                                 pool2[1][0]                      \n","                                                                 pool1[3][0]                      \n","                                                                 pool1[5][0]                      \n","__________________________________________________________________________________________________\n","reshape_83 (Reshape)            (None, 4, 300)       0           question_concat[0][0]            \n","__________________________________________________________________________________________________\n","reshape_84 (Reshape)            (None, 4, 300)       0           answer_concat[0][0]              \n","__________________________________________________________________________________________________\n","question_dropout (Dropout)      (None, 4, 300)       0           reshape_83[0][0]                 \n","__________________________________________________________________________________________________\n","answer_dropout (Dropout)        (None, 4, 300)       0           reshape_84[0][0]                 \n","__________________________________________________________________________________________________\n","maximum (Maximum)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","subtract (Subtract)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","average (Average)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","final_concat (Concatenate)      (None, 4, 1800)      0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","                                                                 maximum[0][0]                    \n","                                                                 multiply[0][0]                   \n","                                                                 subtract[0][0]                   \n","                                                                 average[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_85 (Reshape)            (None, 24, 300)      0           final_concat[0][0]               \n","__________________________________________________________________________________________________\n","compatibilites (Dense)          (None, 24, 300)      90000       reshape_85[0][0]                 \n","__________________________________________________________________________________________________\n","self_att_weights (Dense)        (None, 24, 300)      90000       compatibilites[0][0]             \n","__________________________________________________________________________________________________\n","attention_mul (Multiply)        (None, 24, 300)      0           reshape_85[0][0]                 \n","                                                                 self_att_weights[0][0]           \n","__________________________________________________________________________________________________\n","attention (Lambda)              (None, 300)          0           attention_mul[0][0]              \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 1)            301         attention[0][0]                  \n","==================================================================================================\n","Total params: 3,115,201\n","Trainable params: 720,901\n","Non-trainable params: 2,394,300\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"LYSBsFdbCrew","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1187},"outputId":"5dcda0d3-ce62-492b-d762-bc811515469b","executionInfo":{"status":"ok","timestamp":1528645574899,"user_tz":-120,"elapsed":141284,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["BATCH_SIZE = 32 # set to max allowable value\n","EPOCHS = 10*3\n","\n","print('Train...')\n","CNN1.fit(train_X, train_y,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_data=(dev_X, dev_y),\n","          verbose=2,\n","          callbacks=None)\n","\n","score, acc = CNN1.evaluate(test_X, test_y, batch_size=BATCH_SIZE)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n","# save model\n","CNN1.save('cnn_avgpool_final_B.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train...\n","Train on 2593 samples, validate on 495 samples\n","Epoch 1/30\n"," - 10s - loss: 0.6807 - acc: 0.5970 - val_loss: 0.6881 - val_acc: 0.5717\n","Epoch 2/30\n"," - 4s - loss: 0.6732 - acc: 0.5978 - val_loss: 0.6736 - val_acc: 0.5758\n","Epoch 3/30\n"," - 4s - loss: 0.6698 - acc: 0.5966 - val_loss: 0.7051 - val_acc: 0.5758\n","Epoch 4/30\n"," - 4s - loss: 0.6672 - acc: 0.5993 - val_loss: 0.6743 - val_acc: 0.5717\n","Epoch 5/30\n"," - 4s - loss: 0.6613 - acc: 0.6078 - val_loss: 0.6776 - val_acc: 0.5758\n","Epoch 6/30\n"," - 4s - loss: 0.6483 - acc: 0.6317 - val_loss: 0.6731 - val_acc: 0.5838\n","Epoch 7/30\n"," - 4s - loss: 0.6459 - acc: 0.6363 - val_loss: 0.7129 - val_acc: 0.5697\n","Epoch 8/30\n"," - 4s - loss: 0.6332 - acc: 0.6560 - val_loss: 0.7151 - val_acc: 0.5697\n","Epoch 9/30\n"," - 4s - loss: 0.6194 - acc: 0.6545 - val_loss: 0.6695 - val_acc: 0.5778\n","Epoch 10/30\n"," - 4s - loss: 0.6218 - acc: 0.6599 - val_loss: 0.7029 - val_acc: 0.5818\n","Epoch 11/30\n"," - 4s - loss: 0.6170 - acc: 0.6845 - val_loss: 0.7054 - val_acc: 0.5879\n","Epoch 12/30\n"," - 4s - loss: 0.5867 - acc: 0.7046 - val_loss: 0.7096 - val_acc: 0.5677\n","Epoch 13/30\n"," - 4s - loss: 0.5725 - acc: 0.7081 - val_loss: 0.7284 - val_acc: 0.5677\n","Epoch 14/30\n"," - 4s - loss: 0.6212 - acc: 0.6722 - val_loss: 0.7386 - val_acc: 0.5535\n","Epoch 15/30\n"," - 4s - loss: 0.5898 - acc: 0.7003 - val_loss: 0.7117 - val_acc: 0.5778\n","Epoch 16/30\n"," - 4s - loss: 0.5652 - acc: 0.7150 - val_loss: 0.7078 - val_acc: 0.5697\n","Epoch 17/30\n"," - 4s - loss: 0.5485 - acc: 0.7266 - val_loss: 0.7090 - val_acc: 0.5939\n","Epoch 18/30\n"," - 4s - loss: 0.5683 - acc: 0.7069 - val_loss: 0.7041 - val_acc: 0.5758\n","Epoch 19/30\n"," - 4s - loss: 0.5378 - acc: 0.7316 - val_loss: 0.7331 - val_acc: 0.5657\n","Epoch 20/30\n"," - 4s - loss: 0.5403 - acc: 0.7270 - val_loss: 0.7270 - val_acc: 0.5556\n","Epoch 21/30\n"," - 4s - loss: 0.5336 - acc: 0.7324 - val_loss: 0.7158 - val_acc: 0.5636\n","Epoch 22/30\n"," - 4s - loss: 0.5453 - acc: 0.7358 - val_loss: 0.7314 - val_acc: 0.5798\n","Epoch 23/30\n"," - 4s - loss: 0.5209 - acc: 0.7397 - val_loss: 0.7387 - val_acc: 0.5697\n","Epoch 24/30\n"," - 4s - loss: 0.5213 - acc: 0.7455 - val_loss: 0.7075 - val_acc: 0.5818\n","Epoch 25/30\n"," - 4s - loss: 0.5082 - acc: 0.7547 - val_loss: 0.7935 - val_acc: 0.5495\n","Epoch 26/30\n"," - 4s - loss: 0.4917 - acc: 0.7621 - val_loss: 0.7627 - val_acc: 0.5636\n","Epoch 27/30\n"," - 4s - loss: 0.4965 - acc: 0.7586 - val_loss: 0.7839 - val_acc: 0.5616\n","Epoch 28/30\n"," - 4s - loss: 0.5037 - acc: 0.7617 - val_loss: 0.7362 - val_acc: 0.5838\n","Epoch 29/30\n"," - 4s - loss: 0.5158 - acc: 0.7432 - val_loss: 0.7363 - val_acc: 0.5818\n","Epoch 30/30\n"," - 4s - loss: 0.4734 - acc: 0.7786 - val_loss: 0.7391 - val_acc: 0.5879\n","768/880 [=========================>....] - ETA: 0s"],"name":"stdout"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r880/880 [==============================] - 0s 518us/step\n","Test score: 0.8541384447704662\n","Test accuracy: 0.6113636363636363\n"],"name":"stdout"}]},{"metadata":{"id":"sELihXewCt3b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_and_save(CNN1, test_X, X[\"test\"], \"preds/cnn_avgpool_final_B.pred\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CFC61RUkC0AS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["files.download('cnn_avgpool_final_B.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QioWPy7WC00T","colab_type":"text"},"cell_type":"markdown","source":["##final BiGRU model"]},{"metadata":{"id":"2jQxs3s0C20-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1326},"outputId":"5665af38-baed-470d-a82f-fdd8cf250c78","executionInfo":{"status":"ok","timestamp":1528742522691,"user_tz":-120,"elapsed":9042,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["#\n","# BiGRU classifer\n","#\n","from keras.optimizers import *\n","sgd = SGD(lr=0.1, momentum=0.1, decay=0.99, nesterov=True)\n","#adagrad = Adagrad(lr=0.5, epsilon=None, decay=0.09)\n","activation = 'elu'\n","padding = 'valid'\n","filters = 300\n","kernel_size = 3\n","\n","HIDDEN = 300\n","\n","print('Build model...')\n","inputs_q = Input(shape=(MAX_SEQUENCE_LENGTH,), name='question')\n","inputs_a = Input(shape=(MAX_SEQUENCE_LENGTH,), name='answer')\n","\n","# add masking\n","mask = Masking(mask_value=0., name='masking')\n","inputs_q_ = mask(inputs_q)\n","inputs_a_ = mask(inputs_a)\n","\n","embed = Embedding(vocab_size+1, HIDDEN, weights=[embedding_matrix], trainable=False, mask_zero=False, name='embedding')#mask_zero=True,trainable=False\n","embed_q = embed(inputs_q_)\n","embed_a = embed(inputs_a_)\n","\n","# biGRU one\n","gru_q1 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(embed_q)\n","gru_a1 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(embed_a)\n","\n","pool1 = GlobalMaxPooling1D(name='pool1') #MAX\n","pool1_q = pool1(gru_q1)\n","pool1_a = pool1(gru_a1)\n","\n","#outs = Dot(axes=-1,normalize=True)([pool1_q, pool1_a])\n","\n","# biGRU two\n","gru_q2 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(gru_q1)\n","gru_a2 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(gru_a1)\n","\n","pool2 = GlobalMaxPooling1D(name='pool2') #MAX\n","pool2_q = pool2(gru_q1)\n","pool2_a = pool2(gru_a1)\n","\n","# concatenations\n","q_ = concatenate([pool1_q, pool2_q], name='question_concat')\n","a_ = concatenate([pool1_a, pool2_q], name='answer_concat')\n","re_q = Reshape((-1, HIDDEN))(q_)\n","re_a = Reshape((-1, HIDDEN))(a_)\n","q = Dropout(rate=0.25, name='question_dropout')(re_q)#(q_)\n","a = Dropout(rate=0.25, name='answer_dropout')(re_a)#(a_)\n","\n","qa_mul = multiply([q, a], name='multiply') \n","qa_sub = subtract([q, a], name='subtract')\n","qa_max = maximum([q, a], name='maximum')\n","qa_avg = average([q, a], name='average')\n","concat = concatenate([q, a, qa_max, qa_mul, qa_sub, qa_avg], name='final_concat')\n","\n","# attention block - multi-dimensional self-attention\n","reshaped = Reshape((-1, HIDDEN))(concat)\n","compatibilities = Dense(HIDDEN, activation='elu', use_bias=False, name='compatibilites')(reshaped)\n","attention_weights = Dense(HIDDEN, activation='softmax', use_bias=False, name='self_att_weights')(compatibilities)\n","attention_ = multiply([reshaped, attention_weights], name='attention_mul')\n","attention = Lambda(lambda x: K.sum(x, axis=1), name=\"attention\")(attention_)\n","#attention = dot([reshaped, attention_weights], axes=-1, name='attention')\n","\n","hidden_ = Dense(HIDDEN, activation='tanh', name='final_dense_1')(attention)\n","#hidden_2 = Dense(HIDDEN, activation='elu', name='final_dense_2')(hidden_1)\n","#hidden_ = Dropout(rate=0.25, name=\"hidden_dropout\")(hidden_2)\n","#hidden = BatchNormalization()(hidden_)\n","\n","preds = Dense(1, activation='sigmoid', name='predictions')(attention)#(hidden_)\n","\n","BiGRU = Model(inputs=[inputs_q, inputs_a], outputs=[preds])\n","# try using different optimizers and different optimizer configs\n","BiGRU.compile(loss='binary_crossentropy',\n","              optimizer='adam',#'adadelta',\n","              metrics=['accuracy']) # add mean_average_precision ?\n","print(BiGRU.summary())"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Build model...\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","question (InputLayer)           (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","answer (InputLayer)             (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","masking (Masking)               (None, 100)          0           question[0][0]                   \n","                                                                 answer[0][0]                     \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 100, 300)     2394300     masking[0][0]                    \n","                                                                 masking[1][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 100, 600)     1083600     embedding[0][0]                  \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 100, 600)     1083600     embedding[1][0]                  \n","__________________________________________________________________________________________________\n","pool1 (GlobalMaxPooling1D)      (None, 600)          0           bidirectional_1[0][0]            \n","                                                                 bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","pool2 (GlobalMaxPooling1D)      (None, 600)          0           bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","question_concat (Concatenate)   (None, 1200)         0           pool1[0][0]                      \n","                                                                 pool2[0][0]                      \n","__________________________________________________________________________________________________\n","answer_concat (Concatenate)     (None, 1200)         0           pool1[1][0]                      \n","                                                                 pool2[0][0]                      \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 4, 300)       0           question_concat[0][0]            \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 4, 300)       0           answer_concat[0][0]              \n","__________________________________________________________________________________________________\n","question_dropout (Dropout)      (None, 4, 300)       0           reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","answer_dropout (Dropout)        (None, 4, 300)       0           reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","maximum (Maximum)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","subtract (Subtract)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","average (Average)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","final_concat (Concatenate)      (None, 4, 1800)      0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","                                                                 maximum[0][0]                    \n","                                                                 multiply[0][0]                   \n","                                                                 subtract[0][0]                   \n","                                                                 average[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 24, 300)      0           final_concat[0][0]               \n","__________________________________________________________________________________________________\n","compatibilites (Dense)          (None, 24, 300)      90000       reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","self_att_weights (Dense)        (None, 24, 300)      90000       compatibilites[0][0]             \n","__________________________________________________________________________________________________\n","attention_mul (Multiply)        (None, 24, 300)      0           reshape_3[0][0]                  \n","                                                                 self_att_weights[0][0]           \n","__________________________________________________________________________________________________\n","attention (Lambda)              (None, 300)          0           attention_mul[0][0]              \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 1)            301         attention[0][0]                  \n","==================================================================================================\n","Total params: 4,741,801\n","Trainable params: 2,347,501\n","Non-trainable params: 2,394,300\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"2VwMW3oaC6sF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1187},"outputId":"938b51c3-a0b7-43e9-f47a-d6bd35739ac7","executionInfo":{"status":"ok","timestamp":1528645947992,"user_tz":-120,"elapsed":339563,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["BATCH_SIZE = 32 # set to max allowable value\n","EPOCHS = 10*3\n","\n","print('Train...')\n","BiGRU.fit(train_X, train_y,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_data=(dev_X, dev_y),\n","          verbose=2,\n","          callbacks=None)\n","\n","score, acc = BiGRU.evaluate(test_X, test_y, batch_size=BATCH_SIZE)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n","# save model\n","BiGRU.save('bigru_maxpool_final_B.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train...\n","Train on 2593 samples, validate on 495 samples\n","Epoch 1/30\n"," - 17s - loss: 0.6714 - acc: 0.5943 - val_loss: 0.6778 - val_acc: 0.5717\n","Epoch 2/30\n"," - 11s - loss: 0.6362 - acc: 0.6155 - val_loss: 0.7571 - val_acc: 0.5717\n","Epoch 3/30\n"," - 11s - loss: 0.6057 - acc: 0.6834 - val_loss: 0.6661 - val_acc: 0.5980\n","Epoch 4/30\n"," - 11s - loss: 0.5626 - acc: 0.7181 - val_loss: 0.6601 - val_acc: 0.6040\n","Epoch 5/30\n"," - 11s - loss: 0.5259 - acc: 0.7493 - val_loss: 0.6951 - val_acc: 0.5596\n","Epoch 6/30\n"," - 11s - loss: 0.5138 - acc: 0.7698 - val_loss: 0.6663 - val_acc: 0.5939\n","Epoch 7/30\n"," - 11s - loss: 0.5015 - acc: 0.7682 - val_loss: 0.6854 - val_acc: 0.5919\n","Epoch 8/30\n"," - 11s - loss: 0.4807 - acc: 0.7802 - val_loss: 0.6923 - val_acc: 0.5657\n","Epoch 9/30\n"," - 11s - loss: 0.4680 - acc: 0.7813 - val_loss: 0.6833 - val_acc: 0.5758\n","Epoch 10/30\n"," - 11s - loss: 0.4375 - acc: 0.8118 - val_loss: 0.7031 - val_acc: 0.5758\n","Epoch 11/30\n"," - 11s - loss: 0.4150 - acc: 0.8122 - val_loss: 0.7076 - val_acc: 0.5616\n","Epoch 12/30\n"," - 11s - loss: 0.4148 - acc: 0.8187 - val_loss: 0.7470 - val_acc: 0.5455\n","Epoch 13/30\n"," - 11s - loss: 0.4030 - acc: 0.8218 - val_loss: 0.7225 - val_acc: 0.5535\n","Epoch 14/30\n"," - 11s - loss: 0.3764 - acc: 0.8396 - val_loss: 0.7235 - val_acc: 0.5535\n","Epoch 15/30\n"," - 11s - loss: 0.3891 - acc: 0.8272 - val_loss: 0.7473 - val_acc: 0.5859\n","Epoch 16/30\n"," - 11s - loss: 0.3552 - acc: 0.8496 - val_loss: 0.7562 - val_acc: 0.5697\n","Epoch 17/30\n"," - 11s - loss: 0.3800 - acc: 0.8361 - val_loss: 0.7491 - val_acc: 0.5919\n","Epoch 18/30\n"," - 11s - loss: 0.3490 - acc: 0.8627 - val_loss: 0.7394 - val_acc: 0.5919\n","Epoch 19/30\n"," - 11s - loss: 0.3159 - acc: 0.8673 - val_loss: 0.7812 - val_acc: 0.5717\n","Epoch 20/30\n"," - 11s - loss: 0.3162 - acc: 0.8731 - val_loss: 0.8039 - val_acc: 0.5697\n","Epoch 21/30\n"," - 11s - loss: 0.3231 - acc: 0.8716 - val_loss: 0.7892 - val_acc: 0.5919\n","Epoch 22/30\n"," - 11s - loss: 0.3060 - acc: 0.8735 - val_loss: 0.8234 - val_acc: 0.5919\n","Epoch 23/30\n"," - 11s - loss: 0.2860 - acc: 0.8874 - val_loss: 0.7966 - val_acc: 0.5919\n","Epoch 24/30\n"," - 11s - loss: 0.2808 - acc: 0.8878 - val_loss: 0.8716 - val_acc: 0.5697\n","Epoch 25/30\n"," - 11s - loss: 0.2845 - acc: 0.8855 - val_loss: 0.8872 - val_acc: 0.5980\n","Epoch 26/30\n"," - 11s - loss: 0.2554 - acc: 0.8974 - val_loss: 0.9935 - val_acc: 0.5434\n","Epoch 27/30\n"," - 11s - loss: 0.2432 - acc: 0.9109 - val_loss: 0.8957 - val_acc: 0.5939\n","Epoch 28/30\n"," - 11s - loss: 0.2383 - acc: 0.9132 - val_loss: 0.8869 - val_acc: 0.6000\n","Epoch 29/30\n"," - 11s - loss: 0.2659 - acc: 0.8924 - val_loss: 0.8568 - val_acc: 0.5879\n","Epoch 30/30\n"," - 11s - loss: 0.2507 - acc: 0.9009 - val_loss: 0.9135 - val_acc: 0.5798\n","416/880 [=============>................] - ETA: 0s"],"name":"stdout"},{"output_type":"stream","text":["880/880 [==============================] - 1s 1ms/step\n","Test score: 0.8822599822824652\n","Test accuracy: 0.6\n"],"name":"stdout"}]},{"metadata":{"id":"wgrov-FvC_tf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_and_save(BiGRU, test_X, X[\"test\"], \"preds/bigru_maxpool_final_B.pred\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yTkAUV8jDCYI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["files.download('bigru_maxpool_final_B.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hTOYEbFuDC-B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1349},"outputId":"ff2459d4-d702-40c6-9c44-1919632683c4","executionInfo":{"status":"ok","timestamp":1528646000933,"user_tz":-120,"elapsed":10641,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["#\n","# BiGRU average pooling\n","#\n","from keras.optimizers import *\n","sgd = SGD(lr=0.1, momentum=0.1, decay=0.99, nesterov=True)\n","#adagrad = Adagrad(lr=0.5, epsilon=None, decay=0.09)\n","activation = 'elu'\n","padding = 'valid'\n","filters = 300\n","kernel_size = 3\n","\n","HIDDEN = 300\n","\n","print('Build model...')\n","inputs_q = Input(shape=(MAX_SEQUENCE_LENGTH,), name='question')\n","inputs_a = Input(shape=(MAX_SEQUENCE_LENGTH,), name='answer')\n","\n","# add masking\n","mask = Masking(mask_value=0., name='masking')\n","inputs_q_ = mask(inputs_q)\n","inputs_a_ = mask(inputs_a)\n","\n","embed = Embedding(vocab_size+1, HIDDEN, weights=[embedding_matrix], trainable=False, mask_zero=False, name='embedding')#mask_zero=True,trainable=False\n","embed_q = embed(inputs_q_)\n","embed_a = embed(inputs_a_)\n","\n","# biGRU one\n","gru_q1 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(embed_q)\n","gru_a1 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(embed_a)\n","\n","pool1 = GlobalAveragePooling1D(name='pool1')\n","pool1_q = pool1(gru_q1)\n","pool1_a = pool1(gru_a1)\n","\n","# biGRU two\n","gru_q2 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(gru_q1)\n","gru_a2 = Bidirectional(myGRU(HIDDEN, return_sequences=True), merge_mode=\"concat\")(gru_a1)\n","\n","pool2 = GlobalAveragePooling1D(name='pool2')\n","pool2_q = pool2(gru_q1)\n","pool2_a = pool2(gru_a1)\n","\n","# concatenations\n","q_ = concatenate([pool1_q, pool2_q], name='question_concat')\n","a_ = concatenate([pool1_a, pool2_q], name='answer_concat')\n","re_q = Reshape((-1, HIDDEN))(q_)\n","re_a = Reshape((-1, HIDDEN))(a_)\n","q = Dropout(rate=0.25, name='question_dropout')(re_q)#(q_)\n","a = Dropout(rate=0.25, name='answer_dropout')(re_a)#(a_)\n","\n","qa_mul = multiply([q, a], name='multiply') \n","qa_sub = subtract([q, a], name='subtract')\n","qa_max = maximum([q, a], name='maximum')\n","qa_avg = average([q, a], name='average')\n","concat = concatenate([q, a, qa_max, qa_mul, qa_sub, qa_avg], name='final_concat')\n","\n","# attention block - multi-dimensional self-attention\n","reshaped = Reshape((-1, HIDDEN))(concat)\n","compatibilities = Dense(HIDDEN, activation='elu', use_bias=False, name='compatibilites')(reshaped)\n","attention_weights = Dense(HIDDEN, activation='softmax', use_bias=False, name='self_att_weights')(compatibilities)\n","attention_ = multiply([reshaped, attention_weights], name='attention_mul')\n","attention = Lambda(lambda x: K.sum(x, axis=1), name=\"attention\")(attention_)\n","#attention = dot([reshaped, attention_weights], axes=-1, name='attention')\n","\n","hidden_ = Dense(HIDDEN, activation='tanh', name='final_dense_1')(attention)\n","#hidden_2 = Dense(HIDDEN, activation='elu', name='final_dense_2')(hidden_1)\n","#hidden_ = Dropout(rate=0.25, name=\"hidden_dropout\")(hidden_2)\n","#hidden = BatchNormalization()(hidden_)\n","\n","preds = Dense(1, activation='sigmoid', name='predictions')(attention)#(hidden_)\n","\n","BiGRU1 = Model(inputs=[inputs_q, inputs_a], outputs=[preds])\n","# try using different optimizers and different optimizer configs\n","BiGRU1.compile(loss='binary_crossentropy',\n","              optimizer='adam',#'adadelta',\n","              metrics=['accuracy']) # add mean_average_precision ?\n","print(BiGRU1.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build model...\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","question (InputLayer)           (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","answer (InputLayer)             (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","masking (Masking)               (None, 100)          0           question[0][0]                   \n","                                                                 answer[0][0]                     \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 100, 300)     2394300     masking[0][0]                    \n","                                                                 masking[1][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_65 (Bidirectional (None, 100, 600)     1083600     embedding[0][0]                  \n","__________________________________________________________________________________________________\n","bidirectional_66 (Bidirectional (None, 100, 600)     1083600     embedding[1][0]                  \n","__________________________________________________________________________________________________\n","pool1 (GlobalAveragePooling1D)  (None, 600)          0           bidirectional_65[0][0]           \n","                                                                 bidirectional_66[0][0]           \n","__________________________________________________________________________________________________\n","pool2 (GlobalAveragePooling1D)  (None, 600)          0           bidirectional_65[0][0]           \n","__________________________________________________________________________________________________\n","question_concat (Concatenate)   (None, 1200)         0           pool1[0][0]                      \n","                                                                 pool2[0][0]                      \n","__________________________________________________________________________________________________\n","answer_concat (Concatenate)     (None, 1200)         0           pool1[1][0]                      \n","                                                                 pool2[0][0]                      \n","__________________________________________________________________________________________________\n","reshape_89 (Reshape)            (None, 4, 300)       0           question_concat[0][0]            \n","__________________________________________________________________________________________________\n","reshape_90 (Reshape)            (None, 4, 300)       0           answer_concat[0][0]              \n","__________________________________________________________________________________________________\n","question_dropout (Dropout)      (None, 4, 300)       0           reshape_89[0][0]                 \n","__________________________________________________________________________________________________\n","answer_dropout (Dropout)        (None, 4, 300)       0           reshape_90[0][0]                 \n","__________________________________________________________________________________________________\n","maximum (Maximum)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","subtract (Subtract)             (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","average (Average)               (None, 4, 300)       0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","__________________________________________________________________________________________________\n","final_concat (Concatenate)      (None, 4, 1800)      0           question_dropout[0][0]           \n","                                                                 answer_dropout[0][0]             \n","                                                                 maximum[0][0]                    \n","                                                                 multiply[0][0]                   \n","                                                                 subtract[0][0]                   \n","                                                                 average[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_91 (Reshape)            (None, 24, 300)      0           final_concat[0][0]               \n","__________________________________________________________________________________________________\n","compatibilites (Dense)          (None, 24, 300)      90000       reshape_91[0][0]                 \n","__________________________________________________________________________________________________\n","self_att_weights (Dense)        (None, 24, 300)      90000       compatibilites[0][0]             \n","__________________________________________________________________________________________________\n","attention_mul (Multiply)        (None, 24, 300)      0           reshape_91[0][0]                 \n","                                                                 self_att_weights[0][0]           \n","__________________________________________________________________________________________________\n","attention (Lambda)              (None, 300)          0           attention_mul[0][0]              \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 1)            301         attention[0][0]                  \n","==================================================================================================\n","Total params: 4,741,801\n","Trainable params: 2,347,501\n","Non-trainable params: 2,394,300\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"b93HA7K6DEiA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":827},"outputId":"7f691869-86f2-4de7-a983-7d7e368b4dec","executionInfo":{"status":"ok","timestamp":1528646231459,"user_tz":-120,"elapsed":230232,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["BATCH_SIZE = 32 # set to max allowable value\n","EPOCHS = 10*2\n","\n","print('Train...')\n","BiGRU1.fit(train_X, train_y,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_data=(dev_X, dev_y),\n","          verbose=2,\n","          callbacks=None)\n","\n","score, acc = BiGRU1.evaluate(test_X, test_y, batch_size=BATCH_SIZE)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n","# save model\n","BiGRU1.save('bigru_avgpool_final_B.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train...\n","Train on 2593 samples, validate on 495 samples\n","Epoch 1/20\n"," - 18s - loss: 0.6782 - acc: 0.5974 - val_loss: 0.6848 - val_acc: 0.5717\n","Epoch 2/20\n"," - 11s - loss: 0.6710 - acc: 0.5978 - val_loss: 0.6765 - val_acc: 0.5717\n","Epoch 3/20\n"," - 11s - loss: 0.6519 - acc: 0.6140 - val_loss: 0.6927 - val_acc: 0.5798\n","Epoch 4/20\n"," - 11s - loss: 0.6353 - acc: 0.6309 - val_loss: 0.6730 - val_acc: 0.5697\n","Epoch 5/20\n"," - 11s - loss: 0.5922 - acc: 0.6799 - val_loss: 0.6790 - val_acc: 0.5737\n","Epoch 6/20\n"," - 11s - loss: 0.5509 - acc: 0.7246 - val_loss: 0.6882 - val_acc: 0.5818\n","Epoch 7/20\n"," - 11s - loss: 0.5261 - acc: 0.7428 - val_loss: 0.7173 - val_acc: 0.5697\n","Epoch 8/20\n"," - 11s - loss: 0.5110 - acc: 0.7563 - val_loss: 0.7265 - val_acc: 0.5475\n","Epoch 9/20\n"," - 11s - loss: 0.4928 - acc: 0.7728 - val_loss: 0.7369 - val_acc: 0.5616\n","Epoch 10/20\n"," - 11s - loss: 0.4756 - acc: 0.7728 - val_loss: 0.7409 - val_acc: 0.5717\n","Epoch 11/20\n"," - 11s - loss: 0.4602 - acc: 0.7813 - val_loss: 0.7474 - val_acc: 0.5818\n","Epoch 12/20\n"," - 11s - loss: 0.4366 - acc: 0.8029 - val_loss: 0.7681 - val_acc: 0.5717\n","Epoch 13/20\n"," - 11s - loss: 0.4343 - acc: 0.8052 - val_loss: 0.7802 - val_acc: 0.5535\n","Epoch 14/20\n"," - 11s - loss: 0.4205 - acc: 0.8052 - val_loss: 0.7844 - val_acc: 0.5778\n","Epoch 15/20\n"," - 11s - loss: 0.4096 - acc: 0.8168 - val_loss: 0.7725 - val_acc: 0.5576\n","Epoch 16/20\n"," - 11s - loss: 0.4012 - acc: 0.8172 - val_loss: 0.8132 - val_acc: 0.5616\n","Epoch 17/20\n"," - 11s - loss: 0.3876 - acc: 0.8168 - val_loss: 0.8402 - val_acc: 0.5596\n","Epoch 18/20\n"," - 11s - loss: 0.3903 - acc: 0.8292 - val_loss: 0.7955 - val_acc: 0.5758\n","Epoch 19/20\n"," - 11s - loss: 0.3665 - acc: 0.8457 - val_loss: 0.7776 - val_acc: 0.5818\n","Epoch 20/20\n"," - 11s - loss: 0.3600 - acc: 0.8396 - val_loss: 0.7912 - val_acc: 0.5838\n","880/880 [==============================] - 1s 1ms/step\n","Test score: 0.6952211661772294\n","Test accuracy: 0.6352272727272728\n"],"name":"stdout"}]},{"metadata":{"id":"PbQc_vMoDITH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_and_save(BiGRU1, test_X, X[\"test\"], \"preds/bigru_avgpool_final_B.pred\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XrWTevH2DK3q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["files.download('bigru_avgpool_final_B.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pccTtIyaDy70","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"31be9561-b35d-404a-b904-125903149019","executionInfo":{"status":"ok","timestamp":1528646273161,"user_tz":-120,"elapsed":552,"user":{"displayName":"Antonio Šajatović","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"108473571148257888406"}}},"cell_type":"code","source":["print(\"finally done!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["finally done!\n"],"name":"stdout"}]},{"metadata":{"id":"SbpjNTPo0wew","colab_type":"text"},"cell_type":"markdown","source":["## Demo"]},{"metadata":{"id":"Ap3f7-7ZsbqF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import textwrap\n","\n","def rank_rel_questions_for_question(model, data, proc_data, q_index):\n","    ind = q_index * 10\n","    example = data[ind : ind+10]\n","    print(\"QUESTION\")\n","    print(\"\\n\".join(textwrap.wrap(example[0][0].body, 120, break_long_words=False)))\n","    print(\"\\nRELATED QUESTIONS\")\n","    for i in range(10):\n","        line = \"{}) {}\".format(i+1, example[i][1].body)\n","        print(\"\\n\".join(textwrap.wrap(line, 120, break_long_words=False)))\n","        print()\n","      \n","    proc_example_q = proc_data[0][ind:ind+10, :]\n","    proc_example_a = proc_data[1][ind:ind+10, :]\n","    proc_example = [proc_example_q, proc_example_a]\n","    \n","    probs, preds = predict(model, proc_example, 10)\n","    probs_preds = list(zip(probs, preds))\n","    ranked_probs_preds = sorted(enumerate(probs_preds), key=lambda x: -x[1][0])\n","    \n","    ranked_answers = []\n","    for rpp in ranked_probs_preds:\n","        idx = rpp[0]\n","        ranked_answers.append((example[idx][1].body, rpp[1][1]))\n","      \n","    print(\"\\nRANKED RELATED QUESTIONS\")\n","    for i in range(len(ranked_answers)):\n","        line = \"{}) {}\".format(i+1, ranked_answers[i][0])\n","        print(\"\\n\".join(textwrap.wrap(line, 120, break_long_words=False)))\n","        print(\"IS RELEVANT? {}\".format(ranked_answers[i][1]))\n","        print()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TEeeQMNFttVW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1733},"outputId":"83bc57a9-54ce-48e6-f27f-3f7c807d39f7","executionInfo":{"status":"ok","timestamp":1528743821524,"user_tz":-120,"elapsed":912,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["rank_rel_questions_for_question(BiGRU, X[\"test\"], test_X, 0)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["QUESTION\n","Can someone suggest a link or explain how to obtain visas for family hoping to go on vacation to The UK and Spain? We\n","are bona fide residents in Qatar by the way. Thank you\n","\n","RELATED QUESTIONS\n","1) Do you know how long it will take to get Schengen Visa from Embassy of Greece? 3 days? 1 week? any idea? Thanks.\n","\n","2) Now that I have your attention (good morning btw ;)... Does anyone know if transit visa's are issued here?\n","\n","3) Hi there. Can anyone tell me if there is a Swiss embassy in Doha ? If so , where is it ? Thanks\n","\n","4) Ok - your nominations please for the \"Most Useless Embassy\" in Qatar? Who should have their little diplomatic flag\n","stuffed up their nostril? Who forgets who pays their salaries to swan around to cocktail parties? Who couldn't get care\n","less about the citizens as long as they get to have a shiny car? Who thinks a visa is a card to go shopping with? Please\n","Give me reasons.... no more than 300 words ... thanks a bundle.\n","\n","5) Hi there, I am coming to doha on Thursday and I know I will need a tourist visa. Someone mentioned that I get it at\n","the airport for 55riyals, is this correct? I saw on the Qatar Government website that you needed evidence of which hotel\n","you would be staying in? But I am staying with friends during my stay? Any advice would be good as I am quite nervous\n","about flying alone and dont want any problems when I arrive! Thanks, Beth :-)\n","\n","6) my sister will be coming over from Abu Dhabi for the Eid, her profession stated in her visa is ARCHITECT, does this\n","qualify for VISA UPON ARRIVAL? if yes, where in the airport should she apply this and how much will be the cost?\n","\n","7) Anyone shopped lately for real estate investment opportunity in Qatar? Can you please share your advice with us. I\n","was told that the Pearl project is being offered by many companies and at a variety of terms. Also, I was wondering if\n","the Pearl is the only place at this time. I checked Damac for Lusiel but I was not convinced for some reason. Anyone\n","looked at the development project in Al-Khor?\n","\n","8) I was in Russia in may and was unpleasantly surprised to find out that my QNB cards didn't work at all, while my\n","Brazilian cards, and Commercial Bank cards worked flawlessly. Of course when I complained to QNB they blamed the Russian\n","side (why Commercial Bank cards worked then?) Did anyone else have had this sort of problems? If yes, what bank and what\n","country?<!--break--<\n","\n","9) I received one letter from spain company with online interview form. I filled and sent. Today I received reply from\n","them along offered letter and they congratulated me for new appointement. For visa process they given me one company\n","name along all contacts. They told all expensis will be reimburse after reach spain. Please guide me is that could true\n","or fraud ?\n","\n","10) Hi Everyone I will be arriving in Doha in the next couple of weeks and will need to rent a car soon after I arrive.\n","I was wondering if anyone knew how easy/difficult it is to do this and what would be the costs? Also names and contacts\n","of rental companies. I will be bringing with me a UK driving Licence and an international driving licence. I will be\n","needing a five door hatchback model, nothing too large or fancy and will be needing to rent for 3 or 4 months. Any\n","advice would be appreciated.\n","\n","\n","RANKED RELATED QUESTIONS\n","1) Now that I have your attention (good morning btw ;)... Does anyone know if transit visa's are issued here?\n","IS RELEVANT? true\n","\n","2) Hi there, I am coming to doha on Thursday and I know I will need a tourist visa. Someone mentioned that I get it at\n","the airport for 55riyals, is this correct? I saw on the Qatar Government website that you needed evidence of which hotel\n","you would be staying in? But I am staying with friends during my stay? Any advice would be good as I am quite nervous\n","about flying alone and dont want any problems when I arrive! Thanks, Beth :-)\n","IS RELEVANT? false\n","\n","3) Do you know how long it will take to get Schengen Visa from Embassy of Greece? 3 days? 1 week? any idea? Thanks.\n","IS RELEVANT? false\n","\n","4) I received one letter from spain company with online interview form. I filled and sent. Today I received reply from\n","them along offered letter and they congratulated me for new appointement. For visa process they given me one company\n","name along all contacts. They told all expensis will be reimburse after reach spain. Please guide me is that could true\n","or fraud ?\n","IS RELEVANT? false\n","\n","5) Hi Everyone I will be arriving in Doha in the next couple of weeks and will need to rent a car soon after I arrive. I\n","was wondering if anyone knew how easy/difficult it is to do this and what would be the costs? Also names and contacts of\n","rental companies. I will be bringing with me a UK driving Licence and an international driving licence. I will be\n","needing a five door hatchback model, nothing too large or fancy and will be needing to rent for 3 or 4 months. Any\n","advice would be appreciated.\n","IS RELEVANT? false\n","\n","6) Hi there. Can anyone tell me if there is a Swiss embassy in Doha ? If so , where is it ? Thanks\n","IS RELEVANT? false\n","\n","7) my sister will be coming over from Abu Dhabi for the Eid, her profession stated in her visa is ARCHITECT, does this\n","qualify for VISA UPON ARRIVAL? if yes, where in the airport should she apply this and how much will be the cost?\n","IS RELEVANT? false\n","\n","8) Ok - your nominations please for the \"Most Useless Embassy\" in Qatar? Who should have their little diplomatic flag\n","stuffed up their nostril? Who forgets who pays their salaries to swan around to cocktail parties? Who couldn't get care\n","less about the citizens as long as they get to have a shiny car? Who thinks a visa is a card to go shopping with? Please\n","Give me reasons.... no more than 300 words ... thanks a bundle.\n","IS RELEVANT? false\n","\n","9) I was in Russia in may and was unpleasantly surprised to find out that my QNB cards didn't work at all, while my\n","Brazilian cards, and Commercial Bank cards worked flawlessly. Of course when I complained to QNB they blamed the Russian\n","side (why Commercial Bank cards worked then?) Did anyone else have had this sort of problems? If yes, what bank and what\n","country?<!--break--<\n","IS RELEVANT? false\n","\n","10) Anyone shopped lately for real estate investment opportunity in Qatar? Can you please share your advice with us. I\n","was told that the Pearl project is being offered by many companies and at a variety of terms. Also, I was wondering if\n","the Pearl is the only place at this time. I checked Damac for Lusiel but I was not convinced for some reason. Anyone\n","looked at the development project in Al-Khor?\n","IS RELEVANT? false\n","\n"],"name":"stdout"}]},{"metadata":{"id":"_5PuDn9ELB3Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":459},"outputId":"57a8ed2b-9bbe-4638-c02c-5d5f5a721b86","executionInfo":{"status":"ok","timestamp":1528743305534,"user_tz":-120,"elapsed":110034,"user":{"displayName":"Tome Radman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102263638256499412849"}}},"cell_type":"code","source":["BATCH_SIZE = 32 # set to max allowable value\n","EPOCHS = 10\n","\n","print('Train...')\n","BiGRU.fit(train_X, train_y,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_data=(dev_X, dev_y),\n","          verbose=2,\n","          callbacks=None)\n","\n","score, acc = BiGRU.evaluate(test_X, test_y, batch_size=BATCH_SIZE)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Train...\n","Train on 2593 samples, validate on 495 samples\n","Epoch 1/10\n"," - 11s - loss: 0.5464 - acc: 0.7358 - val_loss: 0.6530 - val_acc: 0.5980\n","Epoch 2/10\n"," - 11s - loss: 0.5078 - acc: 0.7682 - val_loss: 0.6790 - val_acc: 0.6020\n","Epoch 3/10\n"," - 11s - loss: 0.4732 - acc: 0.7809 - val_loss: 0.6343 - val_acc: 0.6141\n","Epoch 4/10\n"," - 11s - loss: 0.4293 - acc: 0.8076 - val_loss: 0.6688 - val_acc: 0.6020\n","Epoch 5/10\n"," - 11s - loss: 0.3906 - acc: 0.8280 - val_loss: 0.6972 - val_acc: 0.6162\n","Epoch 6/10\n"," - 11s - loss: 0.3732 - acc: 0.8515 - val_loss: 0.7258 - val_acc: 0.6081\n","Epoch 7/10\n"," - 11s - loss: 0.3403 - acc: 0.8635 - val_loss: 0.7135 - val_acc: 0.6081\n","Epoch 8/10\n"," - 11s - loss: 0.3545 - acc: 0.8508 - val_loss: 0.7514 - val_acc: 0.5576\n","Epoch 9/10\n"," - 11s - loss: 0.4004 - acc: 0.8234 - val_loss: 0.7388 - val_acc: 0.6343\n","Epoch 10/10\n"," - 11s - loss: 0.3010 - acc: 0.8801 - val_loss: 0.7438 - val_acc: 0.6263\n","880/880 [==============================] - 1s 1ms/step\n","Test score: 0.7386161966757341\n","Test accuracy: 0.6079545454545454\n"],"name":"stdout"}]}]}